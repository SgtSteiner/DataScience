{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCCION A LAS REDES NEURONALES ARTIFICIALES CON KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los pájaros nos inspiraron para volar, las plantas de bardana inspiraron el velcro e innumerables inventos más se inspiraron en la naturaleza. Parece lógico, entonces, mirar la arquitectura del cerebro en busca de inspiración sobre cómo construir una máquina inteligente. Esta es la idea clave que sirvió de chispa para las *redes neuronales artificiales - RNAs (artificial neuronal networks - ANN)*. Sin embargo, aunque los aviones se inspiraron en los pájaros, no tienen que batir sus alas. De forma similiar, las RNAs se han vuelto gradualmente bastante diferentes de sus primos biológicos. Algunos investigadores incluso argumentan que deberíamos abandonar por completo la analogía biológica (por ejemplo, diciendo \"unidades\" en lugar de \"neuronas\"), para que no restrinjamos nuestra creatividad a sistemas biológicamente plausibles (*podemos obtener lo mejor de ambos mundos estando abiertos a inspiraciones biológicas sin temor a crear modelos biológicamente irreales, siempre que funcionen bien*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las RNAs son el corazón de Deep Learning. Son versátiles, poderosas y escalables, haciéndolas ideales para abordar tareas grandes y altamente complejas de machine learning, tales como la clasificación de billones de imágenes (por ejemplo, Google Images), potenciar los servicios de reconocimiento del habla (por ejemplo, Siri de Apple), recomendar los mejores videos para ver a cientos de millones de usuarios cada dia (por ejemplo, YouTube) o aprendiendo a vencer al campeón del mundo del juego de *Go* jugando millones de partidas contra sí misma (Alpha-Zero de DeepMind)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la primera parte de este capítulo, nos introduciremos en las redes neuronales artificiales, empezando por un rapido recorrido por las primera arquitecturas de RNAs, hasta llegar a los *Perceptrones Multi-Capa PMCs* (*Multi-Layer Perceptrons, MLPs*), que se utilizan mucho en la actualidad (en otros capítulos exploraremos otras arquitecturas). En la segunda parte, echaremos un vistazo a cómo implementar RNAs usando la popular API Keras. Se trata de una API de alto nivel maravillosamente diseñada para la construcción, entrenamiento, evaluación y ejecución de redes neuronales. Pero no nos dejemos engañar por su simplicidad: es lo suficientemente expresiva y flexible para construir una amplia variedad de arquitecturas de redes neuronales. De hecho, probablemente será suficiente para la mayoría de nuestros casos. Además, si alguna vez necesitamos flexibilidad extra, siempre podremos escribir componentes de Keras personalizados usando su API de bajo nivel, como veremos más adelante.\n",
    "\n",
    "Pero primero, retrocedamos en el tiempo para ver cómo surgieron las redes neuronales artificiales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De las neuronas biológicas a las artificiales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorprendentemente, las RNAs existen desde hace bastante poco: fueron introducidas por primera vez en 1943 por el neurofisiólogo Warren McCulloch y el matemático Walter Pitts. En su [Artículo](https://homl.info/43) “A Logical Calculus of Ideas Immanent in Nervous Activity”, McCulloh y Pitts presentaron un modelo computacional simplificado de cómo las neuronas biológicas podrían trabajar juntas en el cerebro de los animales para ejecutar cálculos complejos usando *lógica proposicional*. Esta fue la primera arquitectura de red neuronal artifical. Desde entonces, se han inventado otras muchas arquitecturas, como veremos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los primeros éxitos de las RNAs hasta la década de 1960 llevaron a la creencia generalizada de que pronto estaríamos conversando con máquinas verdaderamente inteligentes. Cuando quedó claro que esa promesa no sería cumplida (al menos durante bastante tiempo), los fondos y la inversión volaron hacia otra parte y las RNAs entraron en un largo invierno. A principio de la década de 1980 se produjo un resurgimiento del interés en el *conexionismo* (el estudio de las redes neuronales), a medida que se inventaron nuevas arquitecturas y se desarrollaron mejores técnicas de entrenamiento. Pero el progreso fue lento y en la década de 1990 se inventaron otras poderosas técnicas de Machine Learning, tales como las Máquinas de Soporte Vectorial. Estas técnicas parecían ofrecer mejores resultados y bases teóricas más solidas que las RNAs, así que una vez más el estudio de las redes neuronales entró en hibernación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, ahora estamos presenciando otra ola de interés en las RNAs. ¿Esta ola se extinguirá como las anteriores? Buieno, exsiten buenas razones para creer que esta ola es diferente y que tendrá un impacto mucho más profundo en nuestras vidas:\n",
    "\n",
    "+ Ahora existe una enorme cantidad de datos disponibles para entrenar a las redes neuronales y las RNAs superan frecuentemente a otras técnicas de ML en problemas muy grandes y complejos.\n",
    "\n",
    "+ El tremendo incremento en poder computacional desde la década de 1990 posibilita ahora entrenar grandes redes neuronales en una cantidad de tiempo razonable. Esto es en parte debido a la Ley de Moore, pero también gracias a la industria del juego, que ha producido por millones poderosas tarjetas GPU.\n",
    "\n",
    "+ Los algoritmos de entrenamiento han sido mejorados. Para ser justos, solo son ligeramente diferentes de los usados en la década de 1990, pero estos pequeños ajustes han tenido un impacto enorme.\n",
    "\n",
    "+ Algunas limitaciones teóricas de las RNAs han resultado ser benignas en la práctica. Por ejemplo, mucha gente pensó que los algoritmos de entrenamiento estaban condenados porque era probable que se atascaran en óptimos locales, pero resulta que esto es bastante raro en la práctica (o cuando es el caso, generalmente están bastante cerca del óptimo global).\n",
    "\n",
    "+ Las RNAs parecen haber entrado en un círculo virtuoso de financiación y progreso. Asombrosos productos basados en RNAs aparecen regularmente en las portadas de las noticias, lo que atrae cada vez más la atención y financiación hacia ellos, resultando en más y más progreso e incluso en más productos asombrosos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuronas biológicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de que discutamos las neuronas artificiales, echemos un rápido vistazo a las neuronas biológicas (representada en la siguiente figura). Es una célula de aspecto inusual que se encuentra en la corteza cerebral animal (por ejemplo, nuestro cerebro), compuesta por un *cuerpo celular*, conteniendo el núcleo y la mayoría de los componentes complejos de la célula, y muchas extensiones ramificadas denominadas *dendritas*, más una larga extensión llamado *axón*. La longitud del axón puede ser solo un poco más largo que el cuerpo de la célula o hasta decenas de miles de veces más largo. Cerca de su extremidad, el axón se divide en muchas ramas llamadas *telodendritas* y en la punta de esas ramificaciones hay minúsculas estructuras llamadas *terminales sinápticas* (o simplemente *sinapsis*), que están conectadas a las dendritas (o directamente al cuerpo de la célula) de otras neuronas. Las neuronas biológicas reciben impulsos eléctricos cortos llamados *señales* de otras neuronas a través de estas sinapsis. Cuando una neurona recibe un número suficiente de señales de otras neuronas en unos pocos milisegundos, dispara sus propias señales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![biological_neuron](images/ch10/biological_neuron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, las neuronas biológicas individuales parecen comportarse de una manera bastante simple, pero están organizadas en un vasta red de billones de neuronas, cada neurona conectada normalmente a miles de otras neuronas. Se pueden realizar cálculos altamente complejos mediante una red de neuronas bastante simples, al igual que un hormiguero puede emerger de los esfuerzos combinados de simples hormigas. La arquitectura de las redes neuronales biológicas (RNB) es todavía objeto de investigación activa, pero se han mapeado algunas partes del cerebro y parece que a menudo las neuronas se organizan en capas consecutivas, como se muestra en la siguiente figura, que representa las múltiples capas de una RNB del córtex humano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![multiple_layers](images/ch10/multiple_layers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculos lógicos con neuronas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warren McCulloch y Walter Pitts propusieron un modelo muy simple de neurona biológica, que posteriormente se conoció como *neurona artificial*: tenía una o mas entradas binarias (on/off) y una salida binaria. La neurona artifical simplemente activa su salida cuando cierto número de sus entradas están activas. MacCulloch y Pitts mostraron que incluso con este modelo simplificado es posible construir una red de neuronas artificiales que pueden calcular cualquier proposición lógica que se quiera. Por ejemplo, construyamos algunas RNAs para ejecutar varios cálculos lógicos (ver siguiente figura), asumiendo que una neurona se activa cuando al menos dos de sus entradas están activas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rna_performing](images/ch10/rna_performing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ La primera red de la izquierda simplemente es la función identidad: si una neurona A está activada, la neurona C también se activa (dado que recibe dos señales de entrada de la neurona A), pero si la neurona A está apagada, la neurona C también está apagada.\n",
    "\n",
    "+ La segunda red ejecuta un AND lógico: la neurona C está activada solo cuando las neuronas A y B están activadas (una única señal de entrada no es suficiente para activar la neurona C).\n",
    "\n",
    "+ La tercera red ejecuta un OR lógico: la neurona C se activa si cualquiera de las neuronas A o B está activa (o ambas).\n",
    "\n",
    "+ Finalmente, si suponemos que una conexión de entrada puede inhibir la actividad de una neurona (como es el caso de las neuronas biológicas), entonces la cuarta red calcula una proposición lógica ligeramente más compleja: la neurona C es activada solo si la neurona A está activada y si la neurona B está apagada. Si la neurona A está activada todo el tiempo, entonces tendremos un NOT lógico: la neurona C está activada cuando la neurona B está apagada, y viceversa.\n",
    "\n",
    "Podemos imaginar fácilmente cómo podemos combinar estas redes para calcular expresiones lógicas complejas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El perceptron es una de las arquitecturas RNA más simples, inventada en 1957 por Frank Rosenblatt. Se basa en una neurona artificial ligeramente diferente (ver la siguiente figura) llamada *unidad lógica de umbral* (*threshold logic unit - TLU*) o algunas veces *unidad de umbral lineal* (*linear threshold unit - LTU*): las entradas y las salidas son ahora números (en lugar de valores binarios on/off) y cada conexión de entrada está asociada con un peso. La TLU calcula una suma ponderada de sus entradas ($z = w_1x_1 + w_2x_2 + \\dots + w_nx_n = x^Tw$) y luego aplica una *función de paso* a esta suma y devuelve el resultado: $h_w(x) = \\text{step}(z)$, donde $z = x^Tw$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TLU](images/ch10/TLU.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función de paso más común usada en los perceptrones es la *función Heaviside*. Algunas veces se usa la función señal en su lugar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![heaviside](images/ch10/heaviside.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una única TLU se puede usar para clasificación binaria lineal simple. Calcula una combinación lineal de las entradas y si el resultado excede un umbral, devuelve la clase positiva y si no devuelve la clase negativa (como un clasificador de regresión logística o un SVM lineal). Por ejemplo, podemos usar una única TLU para clasificar flores de iris basándonos en la longitud y ancho del pétalo (también añadiendo una característica de sesgo extra $x_0 = 1$, como hicimos en anteriores capítulos). En este caso, entrenar una TLU significa encontrar el valor correcto para $w_0$, $w_1$ y $w_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un perceptrón se compone simplemente de una única capa de TLUs (*el nombre de perceptron se usa algunas veces para referirse a una red pequeña con una única TLU*), con cada TLU conectada a todas las entradas. Cuando todas las neuronas de una capa están conectadas a cada neurona de la capa previa (es decir, sus neuronas de entrada), es llamada una *capa conectada completamente* o una *capa densa*. Para representar el hecho de que cada entrada se envía a cada TLU, es común dibujar neuronas de paso especiales llamadas *neuronas de entrada*: simplemente emiten cada entrada que se les proporciona. Todas las neuronas de entrada forman la *capa de entrada*. Además, generalmente se añade una característica de sesgo extra ($x_0 = 1$): es normalmente representada usando un tipo especial de neurona llamada *neurona de sesgo*, que solo emite 1 todo el tiempo. Un perceptrón con dos entradas y tres salidas está representado en la siguiente figura. Este perceptrón puede clasificar simultáneamente instancias en tres clases binarias diferentes, lo que lo convierte en una clasificador de múltiples salidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![perceptron](images/ch10/perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias a la magia del álgebra lineal es posible calcular eficientemente las salidas de una capa de neuronas artificiales para varias instancias a la vez usando la siguiente ecuación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h_{W, b}(X) = \\phi(XW + b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Como siempre, **X** representa la matriz de características de entrada. Tiene una fila por instancia y una columna por característica.\n",
    "\n",
    "+ La matriz de pesos **W** contiene todas los pesos de conexiones excepto los de la neurona de sesgo. Tiene una fila por neurona de entrada y una columna por neurona artificial en la capa.\n",
    "\n",
    "+ El vector de sesgo **b** contiene todas los pesos de conexiones entre la neurona de sesgo y las neuronas artificiales. Tiene un término de sesgo por neurona artificial.\n",
    "\n",
    "+ La función $\\phi$ se denomina *función de activación*: cuando las neuronas artificiales son TLUs, es una función de paso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo se entrena un perceptrón? El algoritmo de entrenamiento del perceptrón propuesto por Frank Rosenblatt se inspiró en gran medida en la *regla de Hebb*. En su libro *The organization of behavior*, publicado en 1949, Donald Hebb sugiere que cuando una neurona biológica a menudo activa otra neurona, la conexión entra ambas se fortalece. Esta idea fue posteriormente resumida por Siegrid Löwel en esta frase pegadiza: \"Las células que se disparan juntas, se conectan juntas\". Esta regla se conoció más tarde como la regla de Hebb (o *aprendizaje hebbiano*); es decir, el peso de conexión entre dos neuronas aumenta siempre que tengan la misma salida. Los perceptrones son entrenados usando una variante de esta regla que tiene en cuenta el error cometido por la red; refuerza las conexiones que ayudan a reducir este error. Más específicamente, el perceptrón recibe una instancia de entrenamiento a la vez y por cada instancia hace sus predicciones. Por cada salida de neurona que produce una predicción errónea, refuerza los pesos de conexión de las entradas que habrían contribuido a la predicción correcta. La regla se muestra en la siguiente ecuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w_{i,j}^{(\\text{siguiente paso})} = w_{i, j} + \\eta(y_j - \\hat{y}_j)x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ $w_{i,j}$ es el peso de conexión entre la i-ésima neurona de entrada y la j-ésima neurona de salida.\n",
    "\n",
    "+ $x_i$ es el i-ésimo valor de entrada de la actual instancia de entrenamiento.\n",
    "\n",
    "+ $\\hat{y}_j$ es la salida de la j-ésima neurona de salida de la actual instancia de entrenamiento.\n",
    "\n",
    "+ $y_j$ es la salido objetivo de la j-ésima neurona de salida de la actual instancia de entrenamiento.\n",
    "\n",
    "+ $\\eta$ es la tasa de aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El límite de decisión de cada neurona de salida es lineal, por tanto los perceptrones son incapaces de patrones complejos de aprendizaje (al igual que los clasificadores de regresión logística). Sin embargo, si las instancias de entrenamiento son linealmente separables, Rosenblatt demostró que este algoritmo convergería a una solución (*tengamos en cuenta que esta solución es generalmente no única: en general cuando los datos son linealmente separables, existe una infinidad de hiperplanos que pueden separarlos*). Esto se denomina *Teorema de convergencia del perceptrón*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn suministra una clase `Perceptron` que implementa una única red de TLU. Puede ser usada muy fácilmente como cabría esperar -por ejemplo, en el dataset de iris:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data[:, (2,3)]  # longitud y ancho de pétalo\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "\n",
    "per_clf = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible que hayas notado el hecho de que el algoritmo de aprendizaje del perceptrón se parece mucho al Descenso de Gradiente Estocástico. De hecho, la clase `Perceptron` de Scikit-Learn es equivalente a usar un `SGDClassifier` con los siguientes hiperparámetros: `loss=\"perceptron\"`, `learning_rate=\"constant\"`, `eta0=1` (tasa de aprendizaje) y `penalty=None` (sin regularización).\n",
    "\n",
    "Tengamos en cuenta que, al contrario que los clasificadores de regresión logística, los perceptrones no devuelve una probabilidad de clase; en su lugar, hacen predicciones basadas en un umbral duro. Esta es una de las buenas razones para preferir la regresión logística sobre los perceptrones.\n",
    "\n",
    "En su monografía de 1969 titulada *Perceptrones*, Marvin Minsky y Seymour Papert destacaron una serie de graves debilidades de los perceptrones, en particular el hecho de que eran incapaces de solventar problemas triviales (por ejemplo, el problema de clasificación de *OR exclusivo (XOR)*; ver el lado izquierdo de la siguiente figura). Por supuesto, esto también es cierto para cualquier otro modelo de clasificación lineal (como los clasificadores de regresión logística), pero los investigadores esperaban mucho más de los perceptrones y su decepción fue grande, y muchos abandoraron las redes neuronales por completo en favor de problemas de alto nivel como lógica, resolución de problemas y búsqueda.\n",
    "\n",
    "Sin embargo, resulta que algunas de las limitaciones de los perceptrones pueden eliminarse apilando múltimes perceptrones. La RNA resultante se denomina *Perceptrón Multi-Capa* (*Multi-Layer Perceptron, MLP*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bitddc70b56f9d74bcebb5cbcc975b589c1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
