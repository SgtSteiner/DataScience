{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capítulo 1. Panorámica del Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link a GitHub](https://github.com/ageron/handson-ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indice\n",
    "\n",
    "+ [¿Qué es Machine Learning?](#Qué-es-Machine-Learning)\n",
    "+ [¿Por qué usar Machine Learning?](#Por-qué-usar-Machine-Learning)\n",
    "+ [Tipos de Sistemas de Machine Learning](#Tipos-de-Sistemas-de-Machine-Learning)\n",
    " + [Aprendizaje supervisado/no supervisado](#Aprendizaje-supervisado-no-supervisado)\n",
    "   + [Aprendizaje supervisado](#Aprendizaje-supervisado)\n",
    "   + [Aprendizaje no supervisado](#Aprendizaje-no-supervisado)\n",
    "   + [Aprendizaje semisupervisado](#Aprendizaje-semisupervisado)\n",
    "   + [Aprendizaje por reforzamiento](#Aprendizaje-por-reforzamiento)\n",
    " + [Aprendizaje por lotes y online](#Aprendizaje-por-lotes-y-online)\n",
    "   + [Aprendizaje por lotes](#Aprendizaje-por-lotes)\n",
    "   + [Aprendizaje online](#Aprendizaje-online)\n",
    " + [Aprendizaje basado en instancia versus basado en modelo](#Aprendizaje-instancia-vs-modelo)\n",
    "   + [Aprendizaje basado en instancia](#Aprendizaje-basado-en-instancia)\n",
    "   + [Aprendizaje basado en modelo](#Aprendizaje-basado-en-modelo)\n",
    "+ [Principales desafíos del Machine Learning](#Principales-desafíos-del-Machine-Learning)\n",
    "  + [Cantidad insuficiente de datos de entrenamiento](#Cantidad-insuficiente-de-datos-de-entrenamiento)\n",
    "  + [Datos de entrenamiento no representativos](#Datos-de-entrenamiento-no-representativos)\n",
    "  + [Datos de pobre calidad](#Datos-de-pobre-calidad)\n",
    "  + [Características irrelevantes](#Características-irrelevantes)\n",
    "  + [Sobreajuste de los datos de entrenamiento](#Sobreajuste-de-los-datos-de-entrenamiento)\n",
    "  + [Subajuste de los datos de entrenamiento](#Subajuste-de-los-datos-de-entrenamiento)\n",
    "  + [Un paso atrás](#Un-paso-atrás)\n",
    "+ [Prueba y validación](#Prueba-y-validación)\n",
    "  + [Ajuste de hiperparámetros y selección de modelo](#Ajuste-de-hiperparámetros-y-selección-de-modelo)\n",
    "  + [Desajuste de datos](#Desajuste-de-datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando la mayoría de las personas escuchan \"Machine Learning\", se imaginan un robot: un mayordomo fiel o un Terminator mortal, dependiendo de a quién se le pregunte. Pero Machine Learning no es solo una fantasía futurista, ya está aquí. De hecho, ha existido durante décadas en algunas aplicaciones especializadas, como el *reconocimiento óptico de caracteres* (OCR). Pero la primera aplicación de ML que realmente se convirtió en popular, mejorando la vida de cientos de millones de personas, surgió en el mundo en la década de 1990: era el *filtro de spam*. No es exactamente un Skynet consciente de sí mismo, pero técnicamente se puede calificar como aprendizaje automático (en realidad, ha aprendido tan bien que ya no es necesario marcar un correo electrónico como spam).\n",
    "\n",
    "Le siguieron cientos de aplicaciones de ML que ahora funcionan silenciosamente con cientos de productos y funciones que usamos regularmente, desde recomendaciones de productos hasta búsqueda por voz. ¿Dónde comienza y dónde termina el aprendizaje automático? ¿Qué significa exactamente que una máquina *aprenda* algo? Si descargo una copia de Wikipedia, ¿mi computadora realmente \"aprendió\" algo? ¿De repente es más inteligente? En este capítulo comenzaremos aclarando qué es el aprendizaje automático y por qué es posible que quiera utilizarlo.\n",
    "\n",
    "Luego, antes de comenzar a explorar el continente de Machine Learning, echaremos un vistazo al mapa y aprenderemos sobre las principales regiones y los hitos más notables: aprendizaje supervisado versus no supervisado, aprendizaje en línea versus aprendizaje por lotes, aprendizaje basado en instancias versus aprendizaje basado en modelos. Luego veremos el flujo de trabajo de un proyecto típico de ML, discutiremos los principales desafíos que puede enfrentar y cubriremos cómo evaluar y ajustar un sistema de Machine Learning.\n",
    "\n",
    "Este capítulo presenta muchos conceptos fundamentales (y jerga) que todo científico de datos debe saber de memoria. Será una descripción general de alto nivel (el único capítulo sin mucho código), todo bastante simple, pero debe asegurarse de que todo esté cristalino antes de continuar con el resto del libro. ¡Así que tome un café y comencemos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es Machine Learning? <a name=\"Qué-es-Machine-Learning\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning es la ciencia (y arte) de programar ordenadores para que puedan *aprender de los datos*.\n",
    "\n",
    "Esta es una definición ligeramente más general:\n",
    "\n",
    "> *Machine learning es el campo de estudio que proporciona a los ordenadores la habilidad de aprender sin ser explícitamente programados (Arthur Samuel, 1959)*\n",
    "\n",
    "Y otra más orientada a la ingeniería:\n",
    "\n",
    "> *Un programa de ordenador se dice que aprende de una experiencia E con respecto a alguna tarea T y alguna medida de la ejecución P, si su ejecución en T, medida por P, mejora con la experiencia E. (Tom Mitchell, 1997)*\n",
    "\n",
    "Por ejemplo, tu filtro de spam es un programa de Machine Learning que puede aprender a marcar spam dados ejemplos de emails de spam (por ejemplo, marcados por usuarios) y ejemplos de emails normales (no spam, también llamados \"*ham*\"). Los ejemplos que el sistema usa para aprender son llamados *conjunto de entrenamiento* (*training set* o *sample*). En ese caso, la tarea T es marcar como spam nuevos mails, la experiencia E son los *datos de entrenamiento* y la medida de la ejecución P necesita ser definida. Por ejemplo, podemos usar el ratio de emails clasificados correctamente. Esta medida particular de la ejecución es llamada *precisión* (*accuracy*) y es utilizada a menudo en las tareas de clasificación.\n",
    "\n",
    "Si solo descargamos una copia de Wikipedia nuestro ordenador tiene muchos más datos, pero no es de repente mejor en ninguna tarea. Por lo tanto, no es Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Por qué usar Machine Learning? <a name=\"Por-qué-usar-Machine-Learning\"></a>\n",
    "\n",
    "Consideremos cómo se podría escribir un filtro de spam usando técnicas de programación tradicionales:\n",
    "\n",
    "1. Primero echaríamos un vistazo a cómo es típicamente el spam. Podemos notar que algunas palabras o frases (como por ejemplo \"para ti\", \"tarjeta de crédito\", \"gratis\" e \"increible\") tienden a aparecer mucho en el asunto. Quizás podríamos notar algunos otros patrones en el nombre del remitente, en el cuerpo del correo, etc.\n",
    "\n",
    "2. Escribiríamos un algoritmo de detección para cada uno de los patrones que has descubierto y el programa marcaría emails como spam si se detectan varios de estos patrones.\n",
    "\n",
    "3. Probaríamos el programa y repetiríamos los pasos 1 y 2 hasta que fuera los suficientemente bueno.\n",
    "\n",
    "![spam_traditional](images/ch01/spam_traditional.png)\n",
    "\n",
    "Dado que el problema no es trivial, nuestro programa se convertirá en un largo listado de complejas reglas, bastante difícil de mantener.\n",
    "\n",
    "En contraste, un filtro de spam basado en técnicas de Machine Learning aprende automáticamente qué palabras y frases son buenos predictores del spam, detectando patrones de palabras inusualmente frecuentes en los ejemplos de spam en comparación con ejemplos normales. El programa es mucho más corto, fácil de mantener y probablemente más preciso.\n",
    "\n",
    "![spam_ml](images/ch01/spam_ml.png)\n",
    "\n",
    "Además, si los spammers advierten que todos sus emails conteniendo la palabra \"gratis\" son bloqueados, podrían empezar a escribir en su lugar \"gratuito\". Un filtro de spam usando técnicas de programación tradicional necesitaría ser actualizado para marcar los emails con la palabra \"gratuito\". Si los spammer siguen trabajando, deberá seguir escribiendo nuevas reglas para siempre. Por el contrario, un filtro de spam basado en técnicas de Machine Learning advertirá automáticamente que \"gratuito\" se ha convertido inusualmente frecuente en el correo spam por los usuarios y los marcará sin tu intervención.\n",
    "\n",
    "![spam_ml_adapt](images/ch01/spam_ml_adapt.png)\n",
    "\n",
    "Otro área donde brilla el Machine Learning es en aquellos problemas demasiado comnplejos para los enfoques tradicionales o donde no disponemos de un algoritmo. Por ejemplo, consideremos el reconocimiento del habla: digamos que queremos empezar escribiendo un simple programa que distinga las palabras \"uno\" y \"dos\". Podríamos codificar un algoritmo que mida la intensidad del sonido y sepa distinguir los unos de los doses. Obviamente esta técnica no escalará a miles de palabras habladas por millones de personas muy diferentes en entornos ruidosos y en docenas de lenguajes. La mejor solución (al menos hoy) es escribir un algoritmo que aprenda por sí mismo, proporcionádole muchos ejemplos de cada palabra.\n",
    "\n",
    "Finalmente, Machine Learning puede ayudar a los humanos a aprender: los algoritmos de ML pueden inspeccionarse para ver lo que han aprendido (aunque para algunos algoritmos esto puede ser complicado). Por ejemplo, una vez que el filtro de spam ha sido entrenado con suficiente spam puede ser inspeccionado fácilmente para revelar la lista de palabras y las combinaciones de éstas que cree que son los mejores predictores de spam. Algunas veces esto revelará relaciones insospechadas o nuevas tendencias y, por lo tanto, nos conducirá a una mejor comprensión del problema.\n",
    "\n",
    "La aplicación de técnica de ML para profundizar en grandes cantidades de datos pueden ayudar a descubrir patrones que no eran evidentes de inmediato. Esto es llamado *minería de datos* (*data mining*)\n",
    "\n",
    "![ml_data_mining](images/ch01/ml_data_mining.png)\n",
    "\n",
    "En resumen, Machine Learning es ideal para:\n",
    "\n",
    "- Problemas donde las soluciones existentes requieran de mucho ajuste manual o grandes listas de reglas: un algoritmo de Machine Learning a menudo puede simplificar el código y una mejor ejecución.\n",
    "- Problemas complejos donde no existe una buena solución usando enfoques tradicionales: las mejores técnicas de Machine Learning pueden encontrar una solución.\n",
    "- Entornos cambiantes: un sistema de Machine Learning puede adaptarse a los nuevos datos.\n",
    "- Obtener revelaciones sobre problemas complejos y grandes cantidades de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Sistemas de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay muchos tipos diferentes de sistemas de Machine Learning que son útiles para clasificarlos en amplias categorías que son:\n",
    "\n",
    "- Si son o no entrenados con supervisión humana (supervisados, no supervisados, semisupervisados y aprendizaje por reforzamiento)\n",
    "- Si pueden o no aprender incrementalmente al vuelo (aprendizaje online versus por lotes)\n",
    "- Si pueden o no trabajar simplemente comparando nuevos puntos de datos para conocer nuevos puntos de datos, en lugar de detectar patrones en los datos de entrenamiento y construir un modelo predictivo, al igual que hacen los científicos (aprendizaje basado en instancia versus basado en modelos)\n",
    "\n",
    "Estos criterios no son excluyentes; puedes combinarlos de la forma que se quiera. Por ejemplo, un filtro de spam de última generación puede aprender al vuelo usando un modelo de red neuronal profunda entrenada usando ejemplos de spam y no spam, lo que lo convierte en un sistema de aprendizaje supervisado online basado en modelo.\n",
    "\n",
    "Veamos cada uno de estos criterios un poco más de cerca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendizaje supervisado/no supervisado <a name=\"Aprendizaje-supervisado-no-supervisado\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los sistemas de Machine Learning pueden clasificarse según la cantidad y el tipo de supervisión que reciben durante el entrenamiento. Existen cuatro grandes categorías: aprendizaje supervisado, aprendizaje no supervisado, aprendizaje semisupervisado y aprendizaje por reforzamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aprendizaje supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el aprendizaje supervisado, los datos de entrenamiento que se proporcionan al algoritmo incluyen las soluciones deseadas, llamadas *etiquetas* (*labels*).\n",
    "\n",
    "![ml_supervised_labeled](images/ch01/ml_supervised_labeled.png)\n",
    "\n",
    "Una tarea típica del aprendizaje supervisado es la *clasificación*. El filtro de spam es un buen ejemplo: es entrenado con muchos mails de ejemplo con su *clase* (spam o no spam) y debe aprender cómo clasificar los nuevos emails.\n",
    "\n",
    "Otra típica tarea es predecir un valor numérico *objetivo* (*target*), como puede ser el precio de un coche, dadas una serie de *características* (*features*) (kilometraje, antiguedad, marca, etc.) llamadas *predictores* (*predictors*). Este tipo de tarea se llama *regresión*. Para entrenar al sistema se necesita proporcionar muchos ejemplos de coches, incluyendo tanto los predictores como sus etiquetas (por ejemplo, sus precios).\n",
    "\n",
    "> Dato curioso sobre la regresión: este extraño nombre es un término estadístico introducido por Francis Galton mientras estudiaba el hecho de que los hijos de personas altas tienden a ser más bajos que sus padres. Como los niños eran más bajos, llamó a esta *regresión a la media*. Este nombre se aplicó luego a los métodos que utilizó para analizar las correlaciones entre las variables.\n",
    "\n",
    "En Machine Learning un *atributo* es un tipo de dato (por ejemplo, el kilometraje), mientras que una *característica* tiene varios significados dependiendo del contexto, pero generalmente significa un atributo más su valor (por ejemplo, \"kilometraje = 15.000\"). Sin embargo, muchas personas usan la palabra *atributo* y *característica* de forma equivalente.\n",
    "\n",
    "![regresion](images/ch01/regresion.png)\n",
    "\n",
    "Tengamos en cuenta que algunos algoritmos de regresión pueden ser usados también para la clasificación y viceversa. Por ejemplo, la *regresión logística* se usa comunmente para la clasificación, ya que puede generar un valor que corresponde a la probabilidad de pertenecer a una clase dada (por ejemplo, 20% de probabilidad de ser spam).\n",
    "\n",
    "Aquí tenemos algunos de los algoritmos de aprendizaje supervisado más importantes:\n",
    "\n",
    "+ k-Vecinos más cercanos (*k-Nearest Neighbors*)\n",
    "+ Regresión Lineal\n",
    "+ Regresión Logística\n",
    "+ Maquinas de Soporte Vectorial (*Support Vector Machines* - SVM)\n",
    "+ Arboles de decisión y Bosques Aleatorios (*Decision Trees / Random Forests*)\n",
    "+ Redes neuronales\n",
    "\n",
    "> Algunas arquitecturas de redes neuronales pueden ser no supervisadas, tales como las máquinas autocodificadoras y restringidas de Bolzmann. También pueden ser semisupervisadas como en las redes de creencia profundas y pre-entrenamiento no supervisado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aprendizaje no supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el *aprendizaje no supervisado*, como se puede suponer, los datos de entrenamiento no están etiquetados. El sistema intenta aprender sin un profesor.\n",
    "\n",
    "![ml_no_supervised](images/ch01/ml_no_supervised.png)\n",
    "\n",
    "Aquí hay algunos de los más importantes algoritmos de aprendizaje no supervisado:\n",
    "\n",
    "+ Clustering\n",
    " + k-Means\n",
    " + DBSCAN\n",
    " + Análisis jerárquico de agrupación - *Hierarchical Cluster Analysis (HCA)*\n",
    "+ Detección de anomalías y detección de novedades\n",
    " + One-class SVM\n",
    " + Bosque de soledades (isolation forest)\n",
    "+ Visualización y reducción de dimensionalidad\n",
    " + Análisis de componentes principales (PCA)\n",
    " + Kernel PCA\n",
    " + Embebido local lineal (*Locally-Linear Embedding* - LLE)\n",
    " + t-distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "+ Aprendizaje por regla de asociación\n",
    " + Apriori\n",
    " + Eclat\n",
    " \n",
    "Por ejemplo, digamos que tenemos muchos datos sobre los visitantes de nuestro blog. Puede que queramos ejecutar un algoritmo de *agrupación* (clustering) para intentar detectar grupos de visitantes similares. En ningún momento se le dice al algoritmo a qué grupo pertenece un visitante: encuentra esas conexiones sin nuestra ayuda. Por ejemplo, puede notar que el 40% de los visitantes son hombres que les gustan los comics y leen generalmente nuestro blog por la noche, mientras que el 20% son jóvenes amantes de la ciencia ficción que lo visitan durante el fin de semana, y así sucesivamente. Si usamos un algoritmo de *agrupación jerárquico* podemos subdividir cada grupo en grupos más pequeños. Esto puede ayudarnos a orientar nuestros posts a cada grupo.\n",
    "\n",
    "![clustering](images/ch01/clustering.png)\n",
    "\n",
    "Los algoritmos de *visualización* también son buenos ejemplos de algoritmos de supervisión no supervisados: les proporcionas una gran cantidad de datos completos sin etiquetar y dan como resultado representaciones 2D o 3D de nuestros datos que pueden ser fácilmente visualizados. Estos algoritmos intentan preservar la mayor cantidad de estructura posible (tratando de evitar que los clusters de entrada se superpongan en la visualización), así podemos comprender cómo se organizan los datos y quizás identificar patrones insospechados.\n",
    "\n",
    "A continuación se muestra un ejemplo de visualización t_SNE resaltando los clusters semánticos:\n",
    "\n",
    "![t_sne](images/ch01/t_sne_visualization.png)\n",
    "\n",
    "> Nótese cómo los animales están bastante bien separados de los vehículos, cómo los caballos están cerca de los ciervos pero lejos de las aves, etc.\n",
    "\n",
    "Una tarea relacionada es la *reducción de la dimensionalidad*, en la cual el objetivo es simplificar los datos sin perder demasiada información. Una forma de hacer esto es fusionar varias características correlacionadas en una sola. Por ejemplo, el kilometraje de un coche puede estar muy correlacionado con su antiguedad, así que el algoritmo de reducción de la dimensionalidad las fusionará en una única característica que represente el desgaste del coche. Ha esto se denomina *extracción de características* (feature extraction).\n",
    "\n",
    "A menudo resulta una buena idea intentar reducir la dimensión de nuestros datos de entrenamiento usando un algoritmo de reducción de la dimensionalidad antes de alimentar a otro algoritmo de Machine Learning (como puede ser un algoritmo de aprendizaje supervisado). Se ejecutará mucho más rápido, los datos ocuparán mucho menos espacio en memoria y disco y, el algunos casos, tendrá un mejor rendimiento.\n",
    "\n",
    "Otra importante tarea no supervisada es la *detección de anomalías*. Por ejemplo, la detección de transacciones inusuales de tarjetas de crédito para prevenir el fraude, la detección de defectos de fabricación o la eliminación automática de valores atípicos de un base de datos antes de alimentar a otro algoritmo de aprendizaje. El sistema está entrenado con instancias normales y cuando ve una nueva instancia puede decir si parece normal o es probable que sea una anomalía.\n",
    "\n",
    "![anomaly](images/ch01/anomaly.png)\n",
    "\n",
    "Por último, otra tarea no supervisada común es el *aprendizaje por regla de asociación*, en el cual el objetivo es profundizar en una gran cantidad de datos y descubrir relaciones interesantes entre los atributos. Por ejemplo, supongamos que tenemos un supermercado. Ejecutar una regla de asociación en nuestros registros de ventas puede revelarnos que las personas que compran salsa barbacoa y patatas fritas también suelen comprar carne. Por lo tanto, es posible que queramos colocar estos productos cerca el uno del otro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aprendizaje semisupervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos algoritmos pueden manejar datos de entrenamiento parcialmente etiquetados, normalmente muchos datos sin etiquetar y unos pocos datos etiquetados. Esto se llama *aprendizaje semisupervisado*.\n",
    "\n",
    "Algunos servicios de hospedaje de fotos, como Google Photos, son buenos ejemplos de esto. Una vez que subes todas tus fotos familiares al servicio, reconoce automáticamente que la misma persona A aparece en las fotos 1, 5 y 11, mientras que otra persona B aparece en las fotos 2, 5 y 7. Esta es la parte no supervisada del algoritmo (clustering). Ahora todo lo que necesita el sistema es que le digamos quiénes son esas personas. Solo una etiqueta por persona y es capaz de nombrar a cada uno en cada foto, lo cual es útil en la búsqueda de fotos. \\[*Esto es cuando el sistema trabaja perfectamente. En la práctica, a menudo crea unos pocos clusters por persona y algunas veces mezcla dos personas que parecen similares, así que necesita proporcionarles algunas etiquetas por persona y eliminar manualmente algunos clusters*].\n",
    "\n",
    "![semisupervised](images/ch01/semisupervised.png)\n",
    "\n",
    "La mayoría de los algoritmos semisupervisados son combinaciones de algoritmos supervisados y no supervisados. Por ejemplo, las *redes de creencia profundas (DBNs)* están basadas en componentes no supervisados llamados *redes restringidas de Boltzmann (RBMs)* apiladas una encima de la otra. Las RBMs son entrenadas secuencialmente de una forma no supervisada y posteriormente todo el sistema es ajustado usando técnicas de aprendizaje supervisado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aprendizaje por reforzamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El *aprendizaje por reforzamiento* es una bestia muy diferente. El sistema de aprendizaje, llamado *agente* en este contexto, puede observar el entorno, seleccionar y ejecutar acciones y obtener recompensas a cambio (o penalizaciones en forma de recompensas negativas, como se ven en la figura siguiente). Debe aprender entonces por si mismo la mejor estrategia, llamada *política*, para obtener la mayor recompensa con el tiempo. Una política define que acción debe elegir el agente cuando se encuentra en una situación dada.\n",
    "\n",
    "![reinforcement](images/ch01/reinforcement.png)\n",
    "\n",
    "Por ejemplo, muchos robots implementan algoritmos de aprendizaje por reforzamiento para aprender a caminar. El programa AlphaGo de DeepMind también es un buen ejemplo de Aprendizaje por Reforzamiento: saltó a los titulares en marzo de 2016 cuando venció al campeón del mundo Lee Sedo al juego de *Go*. Aprendió su política ganadora analizando millones de partidas y después jugando muchas partidas contra sí mismo. Téngase en cuenta que su aprendizaje se desactivó durante sus partidas contra el campeón. AlphaGo solo aplicó las políticas que había aprendido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendizaje por lotes y online"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro criterio usado para clasificar los sistemas de Machine Learning es si puede o no el sistema aprender incrementalmente a partir de un flujo de datos entrantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aprendizaje por lotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el *aprendizaje por lotes* el sistema es incapaz de aprender incrementalmente: debe ser entrenado usando todos los datos disponibles. Generalmente esto tomará mucho tiempo y recursos de computación, así que normalmente se realiza offline. Primero se entrena el sistema y después de lanza en producción y se ejecuta sin más aprendizaje, sólo aplica lo aprendido. Esto se llama *aprendizaje offline*.\n",
    "\n",
    "Si queremos que un sistema de aprendizaje por lotes aprenda nuevos datos (como por ejemplo un nuevo tipo de smap), necesitamos entrenar una nueva versión del sistema desde cero en el conjunto de datos completo (no solo los nuevos datos, sino también los antiguos), entonces paramos en anterior sistema y los reemplazamos por el nuevo.\n",
    "\n",
    "Afortunadamente, el proceso global de entrenamiento, evaluación y lanzamiento de un sistema de Machine Learning se puede automatizar con bastante facilidad, por lo que incluso un sistema de aprendizaje por lotes puede adaptarse al cambio. Simplemente actualizamos los datos y entrenamos una nueva versión del sistema desde cero tantas veces como sea necesario.\n",
    "\n",
    "Esta solución es simple y a menudo funciona bien, pero el entrenamiento con el conjunto de datos completo puede llevar muhas horas, así que normalmente solo se entranaría un nuevo sistema cada 24 horas o incluso semanalmente. Si el sistema debe adaptarse rápidamente a datos cambiantes (por ejemplo, para predecir precios de acciones) necesitaremos una solución más reactiva.\n",
    "\n",
    "Además, el entrenamienmto sobre el conjunto de datos completo requieres de muchos recursos de computación (CPU, espacio de memoria, espacio de disco, disco I/O, red I/O, etc.). Si tenemos muchos datos y cada día automatizamos el sistema desde cero, terminará costando mucho dinero. Si la cantidad de datos es enorme, puede ser incluso imposible usar un algoritmo de aprendizaje por lotes.\n",
    "\n",
    "Finalmente, si nuestro sistema necesita ser capaz de aprender autónomamente y tiene recursos limitados (por ejemplo, una aplicación de móvil o un vehículo en Marte), llevar grandes cantidades de datos y consumir muchos recursos para entrenar durante horas cada día es algo bloqueante.\n",
    "\n",
    "Afortunadamente, en todos estos casos la mejor opción es usar algoritmos que son capaces de aprender incrementalmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aprendizaje online"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el *aprendizaje online* entrenamos al sistema incrementalmente alimentando las instancias de datos secuencialmente, ya sea individualmente o en pequeños grupos llamados *mini-lotes*. Cada paso de aprendizaje es rápido y económico, así el sistema puede aprender nuevos datos al vuelo, tal como llegan.\n",
    "\n",
    "![online_learning](images/ch01/online_learning.png)\n",
    "\n",
    "El aprendizaje online es ideal para sistemas que reciben datos como un flujo continuo (por ejemplo, precios de acciones) y necesitan adaptarse rápidamente o autónomamente. También es una buena opción si tienes recursos computacionales limitados: una vez que un sistema online ha aprendido nuevas instancias de datos no las necesita más, asi que podemos descartarlas (a menos que queramos volver a un estado anterior y \"reproducir\" los datos). Esto puede ahorar una gran cantidad de espacio.\n",
    "\n",
    "Los algoritmos de aprendizaje online también puede usarse para entrenar sistemas en grandes conjuntos de datos que no pueden entrenarse en la memoria principal de una máquina (este se llama aprendizaje *out-of-core*). El algoritmo carga parte de los datos, ejecuta una fase de entrenamiento con esos datos y repite el proceso hasta haber ejecutado todos los datos. Generalmente este proceso se realiza offline (por ejemplo, no en sistemas en vivo), por lo que *aprendizaje online* puede ser un nombre confuso. Piensa en ello como si fuera un *aprendizaje incremental*.\n",
    "\n",
    "![online_learning_huge](images/ch01/online_learning_huge.png)\n",
    "\n",
    "Un parámetro importante en los sistemas de aprendizaje online es cómo de rápido debe adaptarse a los datos cambiantes: esto se llama *ratio de aprendizaje*. Si se define un alto ratio de aprendizaje, el sistema se adaptará rápidamente a los nuevos datos, pero también tenderá a olvidar rápidamente los antiguos datos (no queremos que un filtro de spam marque sólo los últimos tipos de spam que mostró). A la inversa, si se define un bajo ratio de aprendizaje, el sistema tendrá más inercia, es decir, aprenderá más despacio pero será menos sensible al ruido en los datos nuevos o a secuencias de de puntos de datos no representativos.\n",
    "\n",
    "Un gran desafío con el aprendizaje online es que si se proporcionan malos datos al sistema, el rendimiento del sistema disminuirá gradualmente. Si estamos hablando de un sistema en vivo, tus clientes lo notarán. Por ejemplo, los malos datos podrían provenir del malfuncionamiento de un sensor de un robot o de alguien que envía spam a un motor de búsqueda para intentar un ranking alto en los resultados de búsqueda. Para reducir este riesgo, necesitas monitorizar el sistema de cerca y desactivar rápidamente el aprendizaje (y posiblemente revertirlo a un estado de trabajo previo) si detectas una caída en el rendimiento. También podrías monitorizar los datos entrantes y reaccionar a los datos anormales (por ejemplo, usando algún algoritmo de detección de anomalías)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendizaje basado en instancia versus basado en modelo <a name=\"Aprendizaje-instancia-vs-modelo\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma de categorizar los sistemas de Machine Learning es por cómo *generalizan*. La mayoría de las tareas de Machine Learning consisten en realizar predicciones. Esto significa que dados unos ejemplos de entrenamiento, el sistema necesita ser capaz de generalizar a otros ejemplos que nunca ha visto antes. Disponer de una buena medida del rendimiento en los datos de entrenamiento es bueno, pero no suficiente; el verdadero objetivo es un buen rendimiento en las nuevas instancias.\n",
    "\n",
    "Existen dos enfoques principales a la generalización: aprendizaje basado en instancia y aprendizaje basado en modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aprendizaje basado en instancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posiblemente, la forma más trivial de aprendizaje es simplemente aprender de memoria. Si tienes que crear un filtro de spam de esta forma, solo marcaría aquellos emails que son idénticos a los emails que ya han marcado previamente los usuarios. No es la peor solución pero ciertamente no es la mejor.\n",
    "\n",
    "En lugar de marcar solo los emails que son idénticos a los ya conocidos, nuestro filtro de spam se podría programar para marcar los emails que son muy similares a los conocidos. Esto requiere una *medida de la similitud* entre dos emails. Una medida muy básica de la similitud entre dos emails podría ser contar el número de palabras que tienen en común. El sistema podría marcar una email si tiene palabras en común con un email conocido marcado anteriormente.\n",
    "\n",
    "Esto es llamado *aprendizaje basado en instancia*: los sistema aprenden ejemplos de memoria, después generalizan a nuevos casos usando medidas de similitud.\n",
    "\n",
    "![instance_based](images/ch01/instance_based.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aprendizaje basado en modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma de generalizar a partir de una conjuntos de ejemplos es construir un modelo de esos ejemplos y después usar dicho modelo para realizar *predicciones*. Esto es llamado *aprendizaje basado en modelo*.\n",
    "\n",
    "![model_based](images/ch01/model_based.png)\n",
    "\n",
    "Por ejemplo, supongamos que queremos saber si el dinero hace a la gente feliz, así que descargamos los datos de *Better Life Index* desde la web de la [OCDE](https://goo.gl/0Eht9W) así como estadísticas del PIB per cápita de la web del [Fondo Monetario Internacional](http://goo.gl/j1MSKe). Unimos ambas tablas y ordenamos por PIB per cápita. La siguiente tabla muestra un extracto de lo que se obtiene:\n",
    "\n",
    "![pib_per_capita](images/ch01/pib_per_capita.png)\n",
    "\n",
    "Vamos a hacer un gráfico de algunos paises aleatorios:\n",
    "\n",
    "![grafico_pib](images/ch01/grafico_pib.png)\n",
    "\n",
    "Parece existir una tendencia. Aunque los datos son *ruidosos* (en parte aleatorios), parece que la satifacción de vida aumenta más o menos linealmente a medida que aumenta el PIB per cápita del país. Por tanto, decidimos modelar la satisfacción de vida como un función lineal del PIB per cápita. Este paso se llama *selección del modelo*: seleccionas un *modelo lineal* de satisfacción de vida con solo un atributo, PIB per cápita.\n",
    "\n",
    "*satisfaccion_de_vida = θ$_0$ + θ$_1$ x PIB_per_capita*\n",
    "\n",
    "Este modelo tiene dos *parámetros de modelo*, θ$_0$ y θ$_1$ (por convención, la letra griega theta θ se usa para representar parámetros de modelo). Ajustando estos parámetros, podemos hacer que nuestro modelo represente cualquier función lineal, como se muestra a continuación:\n",
    "\n",
    "![grafico_pib_lineal](images/ch01/grafico_pib_lineal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de poder usar nuestro modelo, necesitamos definir el valor de los parámetros θ$_0$ y θ$_1$. ¿Cómo podemos saber qué valores hacen que nuestro modelo tenga el mejor rendimiento? Para responder a esta pregunta necesitamos especificar una medida del rendimiento. Podemos definir una *función de utilidad* (*utility function* o *fitness function*) para medir cómo de *bueno* es nuestro modelo o podemos definir una *función de coste* que mida cómo de *malo* es. Para problemas de regresión lineal generalmente usamos una función de coste que mide la distancia entre las predicción del modelo lineal y los ejemplos de entrenamiento; el objetivo es minimizar esta distancia.\n",
    "\n",
    "Aquí es donde entra en juego el algoritmo de Regresión Lineal: le proporcionamos los datos de entrenamiento y encuentra los parámetros que hacen que el modelo lineal se ajuste mejor a nuestros datos. Esto se llama *entrenar* el modelo. En nuestro caso el algoritmo encuentra que el valor de los parámetros óptimos son θ$_0$ = 4,85 y θ$_1$ = 4,91 x 10$^-$$^5$.\n",
    "\n",
    "Ahora el modelo se ajusta a los datos de entrenamiento tanto como es posible (para un modelo lineal), como se puede ver en las siguiente figura:\n",
    "\n",
    "![grafico_lineal_model_fit](images/ch01/grafico_lineal_model_fit.png)\n",
    "\n",
    "Finalmente, ya estamos listos para ejecutar nuestro modelo para hacer predicciones. Por ejemplo, digamos que queremos saber cómo de felices son en Chipre y los datos de la OCDE no tienen respuesta. Afortunadamente, podemos usar nuestro modelo para realizar una buena predicción: miramos el PIB per cápita de Chipre, encontramos que es 22.587 y entonces aplicamos nuestro modelo. Encontramos que el índide de satisfacción de vida es probable que esté entorno a 4,85 + 22.587 x 4,91 x 10$^-$$^5$ = 5,96\n",
    "\n",
    "Para abrir el apetito, a continuación se muestra el código Python que carga los datos, los prepara, crea un gráfico de puntos para su visualización y después entrena un modelo lineal y hace una predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "datapath = os.path.join(\"data\", \"lifesat\", \"\")\n",
    "oecd_bli = pd.read_csv(datapath + \"oecd_bli_2015.csv\", thousands=',')\n",
    "gdp_per_capita = pd.read_csv(datapath + \"gdp_per_capita.csv\",thousands=',',delimiter='\\t',\n",
    "                             encoding='latin1', na_values=\"n/a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_country_stats(oecd_bli, gdp_per_capita):\n",
    "    oecd_bli = oecd_bli[oecd_bli[\"INEQUALITY\"]==\"TOT\"]\n",
    "    oecd_bli = oecd_bli.pivot(index=\"Country\", columns=\"Indicator\", values=\"Value\")\n",
    "    gdp_per_capita.rename(columns={\"2015\": \"GDP per capita\"}, inplace=True)\n",
    "    gdp_per_capita.set_index(\"Country\", inplace=True)\n",
    "    full_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita,\n",
    "                                  left_index=True, right_index=True)\n",
    "    full_country_stats.sort_values(by=\"GDP per capita\", inplace=True)\n",
    "    remove_indices = [0, 1, 6, 8, 33, 34, 35]\n",
    "    keep_indices = list(set(range(36)) - set(remove_indices))\n",
    "    return full_country_stats[[\"GDP per capita\", 'Life satisfaction']].iloc[keep_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "country_stats = prepare_country_stats(oecd_bli, gdp_per_capita)\n",
    "X = np.c_[country_stats[\"GDP per capita\"]]\n",
    "y = np.c_[country_stats[\"Life satisfaction\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the data\n",
    "country_stats.plot(kind='scatter', x=\"GDP per capita\", y='Life satisfaction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a linear model\n",
    "lin_reg_model = sklearn.linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "lin_reg_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.96242338]]\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction for Cyprus\n",
    "X_new = [[22587]] # Cyprus' GDP per capita\n",
    "print(lin_reg_model.predict(X_new)) # outputs [[ 5.96242338]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se hubiera utilizado un algoritmo de aprendizaje basado en instancia en su lugar, habríamos encontrado que Eslovenia tiene el PIB per cápita más cercano al de Chipre (20.732) y, dado que la OCDE nos dice que la satisfacción de vida de Eslovenia es de 5,7, hubiéramos predicho una satisfacción de 5,7 para Chipre. Si nos alejamos un poco y echamos un vistazo a los dos siguientes paises más cercanos, encontraremos a Portugal y España con un índice de satisfacción de vida de 5,1 y 6,5, respectivamente. Promediando estos tres valores obtenemos 5,77 que está bastante cerca de nuestra predicción basada en modelo. Este simple algoritmo se llama regresión de *k-vecinos mas cercanos* (en este ejemplo, k = 3).\n",
    "\n",
    "Reemplazar el modelo de regresión lineal por una regresión k-vecinos más cercanos en el código anterior es tan fácil como reemplazar esta línea:\n",
    "\n",
    "    clf = sklearn.linear_model.LinearRegression()\n",
    "    \n",
    "por esta otra:\n",
    "\n",
    "    clf = sklearn.neighbors.KNeighborsRegressor(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si todo salió bien, nuestro modelo realizará buenas predicciones. Si no, puede que necesitemos usar más atributos (ratio de empleo, salud, polución del aire, etc.), obtener más y mejores datos de entrenamiento o quizás seleccionar un modelo más poderoso (por ejemplo, un modelo de Regresión Polinomial.\n",
    "\n",
    "Como resumen:\n",
    "\n",
    "- Hemos analizado los datos.\n",
    "- Hemos seleccionado un modelo.\n",
    "- Lo hemos entrenado en los datos de entrenamiento (es decir, el algortimo de aprendizaje buscó los valores de los parámetros del modelo que minimizaban una función de coste).\n",
    "- Finalmente, aplicamos el modelo para llevar a cabo predicciones en nuevos casos (esto se llama *inferencia*), esperando que este modelo generalizara bien.\n",
    "\n",
    "Así es como se ve un típico proyecto de Machine Learning. Más adelante experimentaremos esto de primera mano yendo a través de un proyecto end-to-end.\n",
    "\n",
    "Hasta ahora hemos cubierto mucho terreno: ahora sabemos de qué trata realmente Machine Learning, por qué es útil, cuáles son algunas de las categorías más comunes de los sistemas de ML y cuál es el típico flujo de trabajo de un proyecto. Ahora veremos qué puede salir mal en el aprendizaje y a prevenirlo para realizar predicciones precisas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principales desafíos del Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En resumen, dado que nuestra principal tarea es seleccionar un algoritmo de aprendizaje y entrenarlo con algunos datos, las dos cosas que pueden ir mal son un \"mal algoritmo\" y \"malos datos\". Empecemos con ejemplos de malos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad insuficiente de datos de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que un niño pequeño aprenda lo que es una manzana, todo lo que necesitamos hacer es señalar una manzana y decir \"manzana\" (posiblemente tengamos que repetir este procedimientos unas cuantas de veces). Ahora el niño es capaz de reconocer manzanas de todo tipo y colores. Genio.\n",
    "\n",
    "Machine Learning todavía no está en esas; se necesitan muchos datos para que la mayoría de los algoritmos de Machine Learning funcionen adecuadamente. Incluso para problemas muy simples normalmente necesitarás miles de ejemplos y para problemas complejos como el reconocimiento de imágene y caracteres se pueden necesitar millones de ejemplos (a menos que podamos reusar partes de un modelo existente).\n",
    "\n",
    "---\n",
    "**La eficiencia irracional de los datos**\n",
    "\n",
    "En una [famoso artículo](https://www.aclweb.org/anthology/P01-1005.pdf) publicado en 2001, los investigadores de Microsoft Michele Banko y Eric Brill mostraron que cada algoritmo de Machine Learning diferente, incluyen los bastantes simples, funcionaban de manera casi idénticamente bien en un problema complejo de desambiguación (por ejemplo, saber escribir \"tuvo\" o \"tubo\" dependiendo del contexto) de lenguaje natural una vez que recibían suficientes datos, como se puede ver en la siguiente figura:\n",
    "\n",
    "![importancia_datos](images/ch01/importancia_datos.png)\n",
    "\n",
    "Como expressaron los autores: \"estos resultados sugieren que podríamos reconsiderar la compensación entre gastar tiempo y dinero en desarrollar algoritmos versus gastarlo en el desarrollo de un corpus.\"\n",
    "\n",
    "La idea de que importan más los datos que los algoritmos para problemas complejos fue más popularizada por Peter Norvig en un artículo titulado [La eficiencia irracional de los datos](http://goo.gl/q6LaZ8), publicado en 2009. Sin embargo, debe tenerse en cuenta que los conjuntos de datos pequeños y medianos son todavía muy comunes y no es siempre fácil o barato obtener datos de entrenamiento extras, así que no abandonemos los algoritmos por el momento.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos de entrenamiento no representativos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para generalizar correctamente es crucial que nuestros datos de entrenamiento sean representativos de los nuevos casos que queremos generalizar. Esto es cierto tanto para el aprendizaje basado en instancia como para el aprendizaje basado en modelo.\n",
    "\n",
    "Por ejemplo, el conjunto de paises que usamos anteriormente para el entrenamiento del modelo lineal no era perfectamente representativo; algunos paises estaban ausentes. La siguiente figura muestra cómo se verían los datos cuando se añaden los paises ausentes.\n",
    "\n",
    "![nonrepresentative](images/ch01/nonrepresentative.png)\n",
    "\n",
    "Si entrenamos un modelo lineal en estos datos obtendríamos la línea solida, mientras que el modelo antiguo estaría representado por la linea punteada. Como se puede ver, no solo añadir algunos paises ausentes altera significativamente el modelo, sino que parece claro que un modelo lineal simple probablemente nunca va a funcionar del todo bien. Parece que los paises muy ricos no son más felices que los paises moderadamente ricos (de hecho parecen más infelices) y, a la inversa, algunos paises pobres parecen más felices que muchos paises ricos.\n",
    "\n",
    "Mediante el uso de un conjunto de entrenamiento no representativo, entrenamos un modelo que es poco probable que realice predicciones precisas, especialmente para los paises muy pobres y muy ricos.\n",
    "\n",
    "Es crucial usar un conjunto de entrenamiento que sea representativo de los casos que queremos generalizar. A menudo es más difícil de lo que parece: si la muestra es demasiado pequeña tendremos *ruido de muestreo* (es decir, datos no representativos como resultado de la casualidad), pero incluso las muestra muy grandes pueden no ser representativas si el método de muestreo es defectuoso. Esto se denomina *sesgo de muestreo*.\n",
    "\n",
    "---\n",
    "**Un famoso ejemplo de sesgo de muestreo**\n",
    "\n",
    "Quizás el más famoso ejemplo de sesgo de muestreo sucedió durante las elecciones presidenciales de EEUU en 1936, que enfrentó a Landon contra Roosevelt: el *Literary Digest* llevó a cabo una gran encuesta, enviando correos a unos 10 millones de personas. Obtuvo 2,4 millones de respuestas y predijo con una alta confianza que Landon conseguiría el 57% de los votos. En su lugar, Roosevelt ganó con un 62% de los votos. El fallo estaba en el método de muestreo del *Literary Digest*:\n",
    "\n",
    "- En primer lugar, para obtener las direcciones a las que enviar las encuestas, el *Literary Digest* usó directorio telefónicos, listas de subscriptores de revistas, listas de miembros de clubs y similares. Todas estas listas tienden a favorecer a las personas más ricas, aquellas que tienen más probabilidades de votar a los Republicanos (Landon).\n",
    "\n",
    "- En segundo lugar, contestaron menos del 25% de las personas que recibieron la encuesta. De nuevo, esto introdujo un sesgo de muestreo, al descartar a personas que no se preocupan mucho de los políticos, personas a las que no les gusta el *Literary Digest* y otros grupos clave. Este tipo especial de sesgo de muestreo se denomina *sesgo de no respuesta*.\n",
    "\n",
    "Aqui tenemos otro ejemplo: digamos que queremos construir un sistema para reconocer videos de música funk. Una forma de construir nuestro conjunto de entrenamiento es buscar \"musica funk\" en YouTube y usar los videos resultantes. Pero esto asume que el motor de búsqueda de YouTube devuelve un conjunto de videos que son representativos de todos los videos de música funk de YouTube. En realidad, los resultados de la búsqueda estén sesgados hacia artistas populares (y si vivimos en Brasil obtendremos muchos de \"funk carioca\" que no suenan como James Brown). Por otro lado, ¿Cómo podemos obtener un gran conjunto de entrenamiento? \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos de pobre calidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviamente, si nuestros datos de entrenamiento están repletos de errores, valores atípicos y ruido (por ejemplo, debido a mediciones de baja calidad), será más difícil para el sistema detectar los patrones subyacentes, por lo que será menos probable que nuestro sistema se ejecute correctamente. A menudo vale la pena invertir tiempo en limpiar nuestros datos de entrenamiento. La verdad es que la mayoría de los científicos de datos invierten un parte significativa de su tiempo haciendo sólo esto. Por ejemplo:\n",
    "\n",
    "- Si algunas instancias son claramente valores atípicos, puede ser útil simplemente descartarlas o intentar corregir los errores manualmente.\n",
    "\n",
    "- Si a algunas instancias les faltan unas cuantas características (por ejemplo, un 5% de nuestros clientes no especifican su edad), debemos decidir si ignoramos este atributo totalmente, ignorar estas instancias, rellenar los valores faltantes (por ejemplo con la edad media) o entrenar un modelo con la característica y otro sin ella, y así sucesivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Características irrelevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se suele decir, datos de entrada defectuosos generan datos de salida defectuosos. Nuestro sistema sólo será capaz de aprender si los datos de entrenamiento contienen suficientes características relevantes y no demasiadas irrelevantes. Una parte crítica del éxito de un proyecto de Machine Learning es crearse con un buen conjunto de características para entrenarse. Este proceso, llamado *ingeniería de características* (feature engineering), implica:\n",
    "\n",
    "- *Selección de características*: seleccionar las características más útiles para entregar de entre todas las existentes.\n",
    "- *Extracción de características*: combinas las características existentes para producir una más útil (como vimos anteriormente, el algoritmo de reducción de la dimensionalidad puede ayudar).\n",
    "- Creación de nuevas características mediante la recopilación de nuevos datos.\n",
    "\n",
    "Ahora que hemos visto muchos ejemplos de datos malos, echemos un vistazo a un par de ejemplos de malos algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobreajuste de los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digamos que estamos visitando un pais extranjero y el taxista nos estafa. Podríamos estar tentados de decir que *todos* los taxistas de ese país son unos ladrones. La sobregeneralización es algo que los humanos hacemos a menudo y, desafortunadamente, las máquinas pueden caer tambien en la misma trampa si no somos cuidadosos. En Machine Learning esto se denomina *sobreajuste* (overfitting): significa que el modelo funciona bien en los datos de entrenamiento pero no generaliza bien.\n",
    "\n",
    "En la siguiente figura se muestra un ejemplo de modelo de satisfacción de vida polinomial de alto grado que se sobre ajusta fuertemente a los datos de entrenamiento. A pesar de que funciona mucho mejor en los datos de entrenamiento que el modelo lineal simple, ¿realmente confiaría en sus predicciones?\n",
    "\n",
    "![overfitting](images/ch01/overfitting.png)\n",
    "\n",
    "Los modelos complejos como las redes neuronales profundas pueden detectar patrones sutiles en los datos, pero si el conjunto de entrenamiento es ruidoso o si es demasiado pequeño (lo que introduce ruido de muestreo) entonces es probable que el modelo detecte patrones en el ruido mismo. Obviamente estos patrones no generalizarán a nuevas instancias. Por ejemplo, digamos que proporcionamos a nuestro modelo de satisfacción de vida muchos más atributos, incluyendo otros no informativos como el nombre del país. En este caso, un modelo complejo puede detectar patrones como el hecho de que todos los paises en los datos de entrenamiento que contengan una *w* en su nombre tienen una satisfacción mayor de 7: New Zealand (7,3), Norway (7,4), Sweden (7,2) y Switzerland (7,5). ¿Cómo de seguros estaríamos de que esta regla generalizara a Rwanda o Zimbabwe? Obviamente este patrón ocurre en los datos de entrenamiento por pura casualidad, pero el modelo no tiene forma de decir si un patrón es real o simplemente es el resultado de ruido en los datos.\n",
    "\n",
    "El sobreajuste sucede cuando el modelo es demasiado complejo en relación a la cantidad y el ruido de los datos de entrenamiento. Las posibles soluciones son:\n",
    "\n",
    " - Simplificar el modelo selecccionado uno con menos parámetros (por ejemplo, un modelo lineal en lugar de un modelo polinomial de alto grado), reduciendo el número de atributos en los datos de entranamiento o restringiendo el modelo.\n",
    " - Recopilando más datos de entrenamiento.\n",
    " - Reduciendo el ruido en los datos de entrenamiento (por ejemplo, corrigiendo errores de los datos y eliminando valores atípicos).\n",
    " \n",
    "Reducir el modelo para simplificarlo y disminuir el riesgo de sobreajuste se denomina *regularización*. Por ejemplo, el modelo lineal que definimos anteriormente tenía dos parámetros, θ$_0$ y θ$_1$. Esto nos da un algoritmo de aprendizaje de dos *grados de libertad* para adaptar el modelo a los datos de entrenamiento: podemos ajustar tanto la altura (θ$_0$) como la pendiente (θ$_1$) de la línea. Si forzamos θ$_0$ = 0, el algoritmo tendría solo un grado de libertad y sería mucho más difícil ajustar los datos adecuadamente: todo lo que podría hacer es mover la línea arriba y abajo para acercarse lo más posible a las instancias de entrenamiento, para que terminara alrededor de la media. Un modelo muy simple, de hecho. Si permitimos al algoritmo modificar θ$_1$ pero lo forzamos a mantenerlo pequeño, entonces el algoritmo de aprendizaje tendrá efectivamente entre uno y dos grados de libertad. Producirá un modelo más simple que con dos grados de libertad, pero más complejo que con solo uno. Queremos encontrar el equilibrio ideal entre ajustar perfectamente los datos y mantener el modelo lo suficientemente simple para asegurar que generalizá correctamente.\n",
    "\n",
    "La siguiente figura muestra tres modelos: la linea punteada representa el modelo original que ha sido entrenado con unos cuantos paises ausentes, la línea de rayas es nuestro segundo modelo entrenado con todos los paises y la línea sólida es un modelo lineal entrenado con los mismos datos que el primer modelo pero aplicándole una regularización. Podemos ver que la regularización obliga al modelo a tener una menor pendiente, que se ajusta un poco menos a los datos de entrenamiento, pero que actualmente permite generalizar mejor a nuevos ejemplos.\n",
    "\n",
    "![regularizacion](images/ch01/regularizacion.png)\n",
    "\n",
    "La cantidad de regularización a aplicar durante el aprendizaje puede ser controlada por un *hiperparámetro*. Un hiperparámetro es un parámetro del algoritmo de aprendizaje (no del modelo). Como tal, no se ve afectado por el algoritmo de aprendizaje en sí mismo. Debe establecerse previamente al entrenamiento y permanece constante durante el mismo. Si establecemos el hiperparámetro de regularización a un valor muy alto, obtendremos un modelo casi plano (una pendiente próxima a cero); el algoritmo de aprendizaje seguramente no sobreajuste los datos de entrenamiento, pero será menos probable que encuentre una buena solución. El ajuste de hiperparámetros es un parte importante en la construcción de los sistemas de Machine Learning (vermos un ejemplo detallado en capítulos posteriores)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subajuste de los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede suponer, el *subajuste* (underfitting) es lo contrario del sobreajuste: ocurre cuando nuestro modelo es demasiado simple para aprender la estructura subyacente de los datos. Por ejemplo, un modelo lineal de satisfacción de vida es propenso al subajuste; la realidad es simplemente más compleja que el modelo, así que sus predicciones serán obligadamente inexactas, incluso en los datos de entrenamiento.\n",
    "\n",
    "Las principales opciones para corregir este problema son:\n",
    "\n",
    "- Seleccionar un modelo más poderoso, con más parámetros\n",
    "- Proporcionar mejores características al algoritmo de aprendizaje (ingeniería de características)\n",
    "- Reducir las restricciones en el modelo (por ejemplo, reducir el hiperparámetro de regularización)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un paso atrás"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A estas alturas ya sabemos mucho de Machine Learning. Sin embargo, pasamos por tantos conceptos que nos podemos sentir un poco perdidos, así que demos un paso atrás y echemos un vistazo global:\n",
    "\n",
    "- El Machine Learning trata de hacer que las máquina mejoren en algunas tareas aprendiendo de los datos, en lugar de tener que codificar explícitamente las reglas.\n",
    "\n",
    "- Hay muchos tipos diferentes de sistemas de ML: supervisados o no, por lotes u online, basados en instancia o basados en modelo, y así sucesivamente.\n",
    "\n",
    "- En un proyecto de ML recopilamos datos en un conjunto de entrenamiento y proporcionamos dicho conjunto al algoritmo de aprendizaje. Si se trata de un algoritmo basado en modelo se afinan algunos parámetros para ajustar el modelo a los datos de entrenamiento (para hacer buenas predicciones en el conjunto de entrenamiento en sí mismo) y entonces se espera que sea capaz de hacer buenas predicciones en nuevos casos igual de bien. Si se trata de un algoritmo basado en instancia, solo aprende los ejemplos de memoria y generaliza a nuevas instancias comparando las instancias aprendidas usando una medida de similitud.\n",
    "\n",
    "- El sistema no rendirá bien si nuestro conjuntos de entrenamientos con demasiado pequeños o si los datos no son representativos, ruidosos o poblados de características irrelevantes (la basura que entra es la basura que sale). Por último, nuestro modelo necesita no ser demasiado simle (en cuyo caso estaría subajustado) ni demasiado complejo (en cuyo caso estaría sobreajustado).\n",
    "\n",
    "Solo hay un último tema importante que tratar: una vez que hemos entrenado un modelo, no queremos \"esperar\" que solo generalice a nuevos casos. Queremos evaluarlo y afinarlo si es necesario. Veamos cómo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba y validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La única forma se saber cómo de bien generalizará un modelo a nuevos casos en probarlo en nuevos casos. Un manera de hacer esto es implantar el modelo en producción y monitorizar su rendimiento. Esto funciona bien, pero si nuestro modelo es terriblemente malo, los usuario se quejarán, lo cual no es la mejor idea.\n",
    "\n",
    "Una opción mejor es dividir los datos en dos conjuntos: el *conjunto de entrenamiento* y el *conjunto de prueba*. Como sus nombres indican, entrenamos el modelo usando el conjunto de entrenamiento y lo probamos usando el conjunto de prueba. El ratio de error en los nuevos casos se denomina *error de generalización* o error fuera de la muestra (*out-of-sample error*) y al evaluar el modelo en el conjunto de prueba obtenemos una estimación de este error. Este valor nos dice cómo de bien se ejecutará nuestro modelo en instancias que nunca ha visto antes.\n",
    "\n",
    "Si el error de entrenamiento es bajo (es decir, nuestro modelo produce pocos errores en el conjunto de prueba) pero el error de generalización es alto, significa que nuestro modelo está sobreajustando los datos de entrenamiento.\n",
    "\n",
    "Es algo común usar el 80% de los datos para entrenamiento y mantener el 20% restante para probar. Sin embargo, depende del tamaño del conjunto de datos: si contiene 10 millones de instancias, entonces mantener un 1% significa que nuestro conjunto de prueba contendría 100.000 instancias, lo que probablemente es más que suficiente para obtener una buena estimación del error de generalización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste de hiperparámetros y selección de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, evaluar un modelo es bastante simple: solo hay que usar un conjunto de prueba. Ahora supongamos que estamos dudando entre dos modelos (por ejemplo, un modelo lineal y un modelo polinomial): ¿Cómo podemos decidirnos?. Una opción sería entrenar ambos y comparar cómo de bien generalizan usando el conjunto de prueba.\n",
    "\n",
    "Ahora supongamos que el modelo lineal generaliza mejor, pero que queremos aplicar alguna generalización para evitar el sobreajuste. La pregunta es: ¿Cómo elegir el valor del hiperparámetro de regularización? Una opción sería entrenar 100 modelos diferentes usando 100 valores diferentes para este hiperparámetro. Supongamos que encontramos el mejor valor del hiperparámetro que produce un modelo con el menor error de generalización, digamos que sólo el 5% de error.\n",
    "\n",
    "Así que implantamos este modelo en producción, pero desafortunadamenteno se ejecuta también como esperábamos y provoca un 15% de errores. ¿Qué ha pasado?\n",
    "\n",
    "El problema es que medimos el error de generalización múltiples veces en el conjunto de prueba y adaptamos el modelo y los hiperparámetros para generar el mejor modelo *para este conjunto en particular*. Esto significa que el modelo es improbable que se ejecute bien en nuevos datos.\n",
    "\n",
    "Una solución común a este problema se denomina *holdout validation* (método de retención): simplemente reservamos una parte del conjunto de entrenamiento para evaluar diversos modelos candidatos y seleccionar el mejor. Este nuevo conjunto de reserva se denomina *conjunto de validación* (o algunas veces *conjunto de desarrollo*). Más específicamente, entrenamos múltiples modelos con varios hiperparámetros en el conjunto reducido de entrenamiento (es decir, el conjunto de entrenamiento completo menos el conjunto de validación) y seleccionamos el modelo que se ejecute mejor en el conjunto de validación. Después de este proceso de validación de reserva, entrenamos el mejor modelo en el conjunto de entrenamiento completo (incluyendo el conjunto de validación), donde obtenemos el modelo final. Por último, evaluamos este modelo final en el conjunto de prueba para obtener una estimación del error de generalización.\n",
    "\n",
    "Esta solución funciona muy bien generalmente. Sin embargo, si el conjunto de validación es demasiado pequeño las evaluaciones del modelo serán imprecisas: podemos terminar seleccionando un modelo subóptimo por error. Y viceversa, si el conjunto de validación es demasiado grande, el conjunto de entrenamiento restante será mucho más pequeño que el conjunto de entranamiento completo. ¿Por qué es esto malo? Bueno, dado que el modelo final se entrenará en el conjunto de entrenamiento completo, no es lo ideal comparar modelos candidatos entrenados en un conjunto de entrenamiento mucho más pequeño. Sería como seleccionar el velocista más rápido para participar en una maratón. Una forma de resolver este problema es ejecutar una *validación cruzada* (cross-validation) repetidas veces, usando muchos conjuntos pequeños de validación. Cada modelo se evalúa una vez por conjunto de validación y después se entrena en el resto de los datos. Promediando todas las evaluaciones de un modelo obtenemos una medida mucho más precisa de su rendimiento. Sin embargo, hay un inconveniente: el tiempo de entrenamiento se multiplica por el número de conjuntos de validación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desajuste de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algunos casos, es fácil obtener una gran cantidad de datos de entrenamiento, pero no es perfectamente representativo de los datos que se usarán en producción. Por ejemplo, supongamos que queremos crear una app para móvil que tome fotografías de flores y determine automáticamente su especie. Podemos descargar fácilmente millones de fotografías de flores desde la web, pero no serán prefectamente representativas de las fotografías que tomaremos usando la app desde el dispositivo móvil. Quizás solo tengamos 10.000 fotografías representativas (es decir, tomadas con la app). En este caso, la regla más importante que debemos recordar es que el conjunto de validación y el de prueba deben ser tan representativos como sea posible de los datos que esperamos usar en producción, por lo que deben estar compuestos exclusivamente por fotografías representativas: podemos mezclarlas y poner la mitad en el conjunto de validación y la otra mitad en el conjunto de prueba (asegurándonos de que los duplicados o casi duplicados no terminen en ambos conjuntos). Tras entrenar nuestro modelo en las fotografías de la web, si observamos que la ejecución de nuestro modelo en el conjunto de validación es decepcionante no sabremos si es a causa de que el modelo está sobreajustado en el modelo de entrenamiento o es solo debido a desajustes entre las fotografías de la web y las de la app móvil. Una solución es reservar parte de las fotografías de entrenamiento (de la web) en otro conjunto que Andrew Ng denomina *conjunto de entrenamiento-desarrollo* (train-dev set). Después de entrenado el modelo (en el conjunto de entrenamiento, *no* en el de entrenamiento-desarrollo), podemos evaluarlo en el conjunto de entrenamiento-desarrollo: si se ejecuta bien entonces el modelo no está sobreajustado en el conjunto de entrenamiento, por lo que si funciona mal en el conjunto de validación el problema debe venir de un desajuste de datos. Podemos intentar abordar este problema preprocesando las imágenes de la web para hacer que se parezcan más a las fotografías que se tomarán desde la app móvil, y posteriormente reentrenar el modelo. Y viceversa, si el modelo se ejecuta pobremente en el conjunto de entrenamiento-desarrollo, el modelo estará sobreajustado en el conjunto de entrenamiento y deberíamos intentar simplificarlo o regularizarlo, recopilando más datos de entrenamiento y limpiándolos, como discutimos anteriormente.\n",
    "\n",
    "---\n",
    "**Teorema de \"No hay almuerzo gratis\"**\n",
    "\n",
    "Un modelo es una versión simplificada de las obervaciones. Las simplificaciones están destinadas a descartar detalles superfluos que son poco probables que se generalicen a nuevas instancias. Sin embargo, para decidir qué datos descartar y cuáles mantener debemos hacer *asunciones*. Por ejemplo, un modelo lineal hace la asunción de que los datos son fundamentalmente lineales y que la distancia entre las instancias y la línea recta es sólo ruido, el cual puede ser ignorado de forma segura.\n",
    "\n",
    "En un [famoso artículo de 1996](https://homl.info/8), David Wolpert demostró que si no hacemos absolutamente ninguna asunción sobre los datos, no hay razón alguna para preferir un modelo sobre cualquier otro. Esto se denomina teorema de \"No almuerzo gratis\" (NFL, del inglés *No Free Lunch*). Para algunos conjuntos de datos el mejor modelo es el modelo lineal, mientras que para otros conjuntos de datos es una red neuronal. No hay un modelo que *a priori* garantice trabajar mejor (de ahí el nombre del teorema). La única forma de saber con seguridad qué modelo es mejor es evaluar todos ellos. Dado que nos es posible, en la práctica haremos algunas asunciones razonables sobre los datos y evaluaremos solo unos cuantos modelos. Por ejemplo, para tareas simples podemos avaluar modelos lineales con varios niveles de regularización y, para modelos complejos, podemos evaluar varias redes neuronales.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bitddc70b56f9d74bcebb5cbcc975b589c1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
