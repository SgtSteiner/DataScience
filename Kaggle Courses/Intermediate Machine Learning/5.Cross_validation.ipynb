{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje Automático - Intermedio\n",
    "\n",
    "## Cross validation\n",
    "\n",
    "### Introducción\n",
    "\n",
    "En este tutorial aprenderemos cómo usar la **validación cruzada** para medir mejor la ejecución del modelo.\n",
    "\n",
    "El aprendizaje automático es un proceso iterativo. Te enfrentarás a elecciones sobre qué variables predictivas usar, qué tipos de modelos usar, qué argumentos proporcionar a esos modelos, etc. Hasta ahora, has tomado estas decisiones de una manera basada en datos midiendo la calidad del modelo con un conjunto de validación (o reserva).\n",
    "\n",
    "Pero hay algunos inconvenientes en este enfoque. Para entender esto imagina que tienes un conjunto de datos con 5000 filas. Por lo general, mantendrás aproximadamente el 20% de los datos como un conjunto de datos de validación, ó 1000 filas. Pero esto deja alguna posibilidad aleatoria de determinar las puntuaciones del modelo. Es decir, un modelo podría funcionar bien en un conjunto de 1000 filas, incluso si fuera incorrecto en 1000 filas diferentes.\n",
    "\n",
    "En el extremo, puedes imaginar tener solo 1 fila de datos en el conjunto de validación. Si comparas modelos alternativos, ¡cuál de ellos hace las mejores predicciones en un solo punto de datos será sobre todo una cuestión de suerte!\n",
    "\n",
    "En general, cuanto mayor sea el conjunto de validación, menor aleatoriedad (también conocido como \"ruido\") hay en nuestra medida de calidad del modelo y más confiable será. Desafortunadamente, solo podemos obtener un conjunto de validación grande eliminando filas de nuestros datos de entrenamiento y los conjuntos de datos de entrenamiento más pequeños significan modelos peores.\n",
    "\n",
    "### ¿Qué es la validación cruzada?\n",
    "\n",
    "En la **validación cruzada** o *cross-validation*, ejecutamos nuestro proceso de modelado en diferentes subconjuntos de datos para obtener múltiples medidas de calidad del modelo.\n",
    "\n",
    "Por ejemplo, podríamos comenzar dividiendo los datos en 5 partes, cada una de ella correspondiente al 20% del conjunto de datos completo. En este caso, decimos que hemos dividido los datos en 5 \"**folds**\".\n",
    "\n",
    "![cross_validation](./images/cross_validation.png)\n",
    "\n",
    "Luego, ejecutamos un experimento para cada fold:\n",
    "\n",
    "+ En el **Experimento 1**, usamos el primer fold como un conjunto de validación (o reserva) y todo lo demás como datos de entrenamiento. Esto nos da una medida de la calidad del modelo basada en un conjunto de reserva del 20%.\n",
    "+ En el **Experimento 2**, conservamos los datos del segundo fold (y usamos todo excepto el segundo fold para entrenar el modelo). El conjunto de reserva se utiliza para obtener una segunda estimación de la calidad del modelo.\n",
    "+ Repetimos este proceso, usando cada fold una vez como conjunto de reserva. En conjunto, el 100% de los datos se usan como reserva en algún momento y terminamos con una medida de la calidad del modelo que se basa en todas las filas del conjunto de datos (incluso si no usamos todas las filas simultáneamente)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuándo debemos usar la validación cruzada?\n",
    "\n",
    "La validación cruzada proporciona una medida más precisa de la calidad del modelo, lo cual es especialmente importante si estamos tomando muchas decisiones de modelado. Sin embargo, puede llevar más tiempo ejecutarlo, ya que estima varios modelos (uno para cada fold).\n",
    "\n",
    "Entonces, dadas estas contrapartidas, ¿cuándo deberíamos usar cada enfoque?\n",
    "\n",
    "+ Para *conjuntos de datos pequeños*, donde la carga computacional adicional no es un gran problema, debemos ejecutar la validación cruzada.\n",
    "+ Para *conjuntos de datos más grandes*, un solo conjunto de validación es suficiente. Nuestro código se ejecutará más rápido y es posible que tengamos suficientes datos para que haya poca necesidad de reutilizar algunos de ellos para reservarlos.\n",
    "\n",
    "No existe un umbral simple para lo que constituye un conjunto de datos grande versus pequeño. Pero si el modelo tarda unos minutos o menos en ejecutarse, probablemente valga la pena cambiar a validación cruzada.\n",
    "\n",
    "Alternativamente, se puede ejecutar la validación cruzada y ver si las puntuaciones para cada experimento parecen cercanas. Si cada experimento produce los mismos resultados, un solo conjunto de validación es probablemente suficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lee los datos\n",
    "data = pd.read_csv('./input/melbourne-housing-snapshot/melb_data.csv')\n",
    "\n",
    "# Selecciona el subconjunto de predictores\n",
    "cols_to_use = ['Rooms', 'Distance', 'Landsize', 'BuildingArea', 'YearBuilt']\n",
    "X = data[cols_to_use]\n",
    "\n",
    "# Selecciona el objetivo\n",
    "y = data.Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, definimos un pipeline que utiliza un imputador para completar los valores ausentes y un modelo de random forest para hacer predicciones.\n",
    "\n",
    "Si bien es posible hacer una validación cruzada sin pipelines, ¡es bastante difícil! El uso de un pipeline hará que el código sea notablemente sencillo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),\n",
    "                              ('model', RandomForestRegressor(n_estimators=50,\n",
    "                                                              random_state=0))\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos las puntuaciones de validación cruzada con la función `cross_val_score()` de scikit-learn. Establecemos el número de folds con el parámetro `cv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuación MAE:\n",
      " [301628.7893587  303164.4782723  287298.331666   236061.84754543\n",
      " 260383.45111427]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Multiplicamos por -1 ya que sklearn calcula MAE negativos\n",
    "scores = -1 * cross_val_score(my_pipeline, X, y,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"Puntuación MAE:\\n\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro `scoring` elige una medida de la calidad del modelo a usar: en este caso, elegimos el error absoluto medio negativo (MAE). Los documentos de scikit-learn muestran una [lista de opciones](https://scikit-learn.org/stable/modules/model_evaluation.html).\n",
    "\n",
    "Es un poco sorprendente que especifiquemos MAE negativo. Scikit-learn tiene una convención en la que se definen todas las métricas para que un número alto sea mejor. El uso de negativos aquí les permite ser consistentes con esa convención, aunque el MAE negativo es casi desconocido en otros lugares.\n",
    "\n",
    "Generalmente, queremos una sola medida de la calidad del modelo para comparar modelos alternativos. Entonces tomamos el promedio de todas los experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuación media MAE (a través de los experimentos):\n",
      "277707.3795913405\n"
     ]
    }
   ],
   "source": [
    "print(\"Puntuación media MAE (a través de los experimentos):\")\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "El uso de la validación cruzada produce una medida mucho mejor de la calidad del modelo, con el beneficio adicional de hacer nuestro código más limpio: ten en cuenta que ya no necesitamos seguir la pista de conjuntos de entrenamiento y validación separados. Entonces, especialmente para conjuntos de datos pequeños, ¡es una buena mejora!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "\n",
    "En este ejercicio, aprovecharremos lo que aprendido para ajustar un modelo de aprendizaje automático con **validación cruzada**. Trabajaremos con datos de [Housing Prices Competition for Kaggle Learn Users](https://www.kaggle.com/c/home-data-for-ml-course). \n",
    "\n",
    "![Ames Housing dataset image](https://i.imgur.com/lTJVG4e.png)\n",
    "\n",
    "Vamos a cargar los conjuntos de entrenamiento y validación en `X_train`, `X_valid`, `y_train`, e `y_valid`.  El conjunto de pruebas es cargado en `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# lee los datos\n",
    "train_data = pd.read_csv('./input/train.csv', index_col='Id')\n",
    "test_data = pd.read_csv('./input/test.csv', index_col='Id')\n",
    "\n",
    "# elimina columnas con objetivos ausentes, separa objetivo de predictores\n",
    "train_data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = train_data.SalePrice              \n",
    "train_data.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# Selecciona solo las columnas numéricas\n",
    "numeric_cols = [cname for cname in train_data.columns if train_data[cname].dtype in ['int64', 'float64']]\n",
    "X = train_data[numeric_cols].copy()\n",
    "X_test = test_data[numeric_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>548</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>460</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>836</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "Id                                                                          \n",
       "1           60         65.0     8450            7            5       2003   \n",
       "2           20         80.0     9600            6            8       1976   \n",
       "3           60         68.0    11250            7            5       2001   \n",
       "4           70         60.0     9550            7            5       1915   \n",
       "5           60         84.0    14260            8            5       2000   \n",
       "\n",
       "    YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  GarageArea  \\\n",
       "Id                                                    ...               \n",
       "1           2003       196.0         706           0  ...         548   \n",
       "2           1976         0.0         978           0  ...         460   \n",
       "3           2002       162.0         486           0  ...         608   \n",
       "4           1970         0.0         216           0  ...         642   \n",
       "5           2000       350.0         655           0  ...         836   \n",
       "\n",
       "    WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  \\\n",
       "Id                                                                             \n",
       "1            0           61              0          0            0         0   \n",
       "2          298            0              0          0            0         0   \n",
       "3            0           42              0          0            0         0   \n",
       "4            0           35            272          0            0         0   \n",
       "5          192           84              0          0            0         0   \n",
       "\n",
       "    MiscVal  MoSold  YrSold  \n",
       "Id                           \n",
       "1         0       2    2008  \n",
       "2         0       5    2007  \n",
       "3         0       9    2008  \n",
       "4         0       2    2006  \n",
       "5         0      12    2008  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora, hemos aprendido a construir pipelines con scikit-learn. Por ejemplo, el siguiente pipeline usará [`SimpleImputer()`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) para reemplazar los valores ausentes en los datos, antes de usar [`RandomForestRegressor()`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) para entrenar un modelo de random forest para hacer predicciones. Establecemos el número de árboles en el modelo de random forest con el parámetro `n_estimators`, y establecer `random_state` asegura la reproducibilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "my_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', SimpleImputer()),\n",
    "    ('model', RandomForestRegressor(n_estimators=50, random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También aprendimos a usar pipelines en la validación cruzada. El siguiente código utiliza la función [`cross_val_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) para obtener el error absoluto medio (MAE), promediado a partir de cinco folds diferentes. Recordemos que establecemos el número de pliegues con el parámetro `cv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuación media MAE: 18276.410356164386\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Multiplicamos por -1 ya que sklearn calcula MAE negativos\n",
    "scores = -1 * cross_val_score(my_pipeline, X, y,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"Puntuación media MAE:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 1: Escribe una función útil\n",
    "\n",
    "En este ejercicio, utilizaremos la validación cruzada para seleccionar parámetros para un modelo de aprendizaje automático.\n",
    "\n",
    "Comienza escribiendo una función `get_score()` que informe el MAE promedio (en tres folds de validación cruzada) de un pipeline de aprendizaje automático que utiliza:\n",
    "- los datos en `X` e `y` para crear folds,\n",
    "- `SimpleImputer()` (con todos los parámetros dejados por defecto) para reemplazar los valores faltantes, y\n",
    "- `RandomForestRegressor()` (con `random_state = 0`) para ajustar un modelo de bosque aleatorio.\n",
    "\n",
    "El parámetro `n_estimators` suministrado a `get_score()` se usa al establecer el número de árboles en el modelo de random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(n_estimators):\n",
    "    my_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', SimpleImputer()),\n",
    "        ('model', RandomForestRegressor(n_estimators, random_state=0))\n",
    "    ])\n",
    "    scores = -1 * cross_val_score(my_pipeline, X, y,\n",
    "                                  cv=3,\n",
    "                                  scoring='neg_mean_absolute_error')\n",
    "    return scores.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 2: Prueba diferentes valores de parámetros\n",
    "\n",
    "Ahora, utilizarás la función definida en el Paso 1 para evaluar el rendimiento del modelo correspondiente a ocho valores diferentes para el número de árboles en el random forest: 50, 100, 150, ..., 300, 350, 400.\n",
    "\n",
    "Almacena sus resultados en un diccionario de Python `results`, donde `results [i]` es el MAE promedio devuelto por `get_scores (i)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for i in range(1,9):\n",
    "    results[50*i] = get_score(50*i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 3: Encuentra el mejor valor de parámetro\n",
    "\n",
    "Vamos a visualizar los resultados del Paso 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(list(results.keys()), list(results.values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados los resultados, ¿qué valor de `n_estimators` parece mejor para el modelo de random forest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_best = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio, has explorado un método para elegir los parámetros apropiados en un modelo de aprendizaje automático.\n",
    "\n",
    "Si deseas obtener más información sobre [optimización de hiperparámetros](https://en.wikipedia.org/wiki/Hyperparameter_optimization), recomendamos que comiences con **grid search**, que es un método sencillo para determinar la mejor combinación de parámetros para un modelo de aprendizaje automático. Afortunadamente, scikit-learn también contiene una función incorporada [`GridSearchCV()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) que puede hacer el código de grid search muy eficiente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
