{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje Automático - Intermedio\n",
    "\n",
    "## Variables categóricas\n",
    "\n",
    "### Introducción\n",
    "\n",
    "Aprenderemos qué es una variable categórica a través de tres enfoques para manejar este tipo de datos.\n",
    "\n",
    "Una **variable categórica** toma solo un número limitado de valores.\n",
    "\n",
    "+ Considera una encuesta que te pregunta con qué frecuencia desayunas y te ofrece cuatro opciones: \"Nunca\", \"Raramente\", \"La mayoría de los días\" o \"Todos los días\". En este caso, los datos son categóricos porque las respuestas se dividen en un conjunto fijo de categorías.\n",
    "+ Si las personas respondieran a una encuesta sobre qué marca de automóvil poseen, las respuestas estarían en categorías como \"Honda\", \"Toyota\" y \"Ford\". En este caso, los datos también son categóricos.\n",
    "\n",
    "Obtendremos un error si intentamos utilizar estas variables en la mayoría de los modelos de aprendizaje automático en Python sin preprocesarlas primero. En este tutorial, compararemos tres enfoques que podemos usar para preparar nuestros datos categóricos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tres Enfoques\n",
    "\n",
    "#### 1) Eliminar las variables categóricas\n",
    "\n",
    "El enfoque más fácil para tratar con variables categóricas es simplemente eliminarlas del conjunto de datos. Este enfoque solo funcionará bien si las columnas no contienen información útil.\n",
    "\n",
    "#### 2) Label Encoding (Codificación de Etiquetas)\n",
    "\n",
    "**Label encoding** asigna cada valor único a un número entero diferente.\n",
    "\n",
    "![label_encoding](./images/label_encoding.png)\n",
    "\n",
    "Este enfoque supone un orden de las categorías: \"Nunca\" (0) < \"Raramente\" (1) < \"La mayoría de los días\" (2) < \"Todos los días\" (3).\n",
    "\n",
    "Esta suposición tiene sentido en este ejemplo, porque hay una clasificación indiscutible para las categorías. No todas las variables categóricas tienen un orden claro en los valores, pero nos referimos a las que lo hacen como **variables ordinales**. Para los modelos basados en árboles (como árboles de decisión y random forests), podemos esperar que label encoding funcione bien con variables ordinales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) One-Hot Encoding\n",
    "\n",
    "**One-Hot encoding** crea nuevas columnas que indican la presencia (o ausencia) de cada valor posible en los datos originales. Para entender esto, trabajaremos con un ejemplo.\n",
    "\n",
    "![one_hot_encoding](./images/one_hot_encoding.png)\n",
    "\n",
    "En el conjunto de datos original, \"Color\" es una variable categórica con tres categorías: \"Rojo\", \"Amarillo\" y \"Verde\". La codificación one-hot correspondiente contiene una columna para cada valor posible y una fila para cada fila en el conjunto de datos original. Dondequiera que el valor original fuera \"Rojo\", colocamos un 1 en la columna \"Rojo\"; si el valor original era \"Amarillo\", colocamos un 1 en la columna \"Amarillo\", y así sucesivamente.\n",
    "\n",
    "A diferencia de label encoding, la codificación one-hot no asume un orden de las categorías. Por lo tanto, podemos esperar que este enfoque funcione particularmente bien si no hay un orden claro en los datos categóricos (por ejemplo, \"Rojo\" no es ni más ni menos que \"Amarillo\"). Nos referimos a las variables categóricas sin una clasificación intrínseca como **variables nominales**.\n",
    "\n",
    "La codificación one-hot generalmente no funciona bien si la variable categórica tiene una gran cantidad de valores (es decir, generalmente no la usará para variables que toman más de 15 valores diferentes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo, trabajaremos con el conjunto de datos de [Melbourne Housing](https://www.kaggle.com/dansbecker/melbourne-housing-snapshot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\pandas\\core\\frame.py:4097: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Lee los datos\n",
    "data = pd.read_csv('./input/melbourne-housing-snapshot/melb_data.csv')\n",
    "\n",
    "# Separa el objetivo de los predictores\n",
    "y = data.Price\n",
    "X = data.drop(['Price'], axis=1)\n",
    "\n",
    "# Divide los datos en subconjuntos de entrenamiento y validación\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# Elimina las columnas con valores ausentes (enfoque más simple)\n",
    "cols_with_missing = [col for col in X_train_full.columns if X_train_full[col].isnull().any()] \n",
    "X_train_full.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_valid_full.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "# \"Cardinalidad\" significa el número de valores únicos en una columna\n",
    "# Selecciona las columnas categóricas con relativamente baja cardinalidad (conveniente pero arbitrariamente)\n",
    "low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Selecciona las columnas numéricas\n",
    "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Mantiene solo las columnas seleccionadas\n",
    "my_cols = low_cardinality_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Echamos un vistazo a los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Method</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12167</th>\n",
       "      <td>u</td>\n",
       "      <td>S</td>\n",
       "      <td>Southern Metropolitan</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.85984</td>\n",
       "      <td>144.9867</td>\n",
       "      <td>13240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>h</td>\n",
       "      <td>SA</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>-37.85800</td>\n",
       "      <td>144.9005</td>\n",
       "      <td>6380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8413</th>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>-37.79880</td>\n",
       "      <td>144.8220</td>\n",
       "      <td>3755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>u</td>\n",
       "      <td>SP</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>-37.70830</td>\n",
       "      <td>144.9158</td>\n",
       "      <td>8870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>-37.76230</td>\n",
       "      <td>144.8272</td>\n",
       "      <td>4217.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Type Method             Regionname  Rooms  Distance  Postcode  Bedroom2  \\\n",
       "12167    u      S  Southern Metropolitan      1       5.0    3182.0       1.0   \n",
       "6524     h     SA   Western Metropolitan      2       8.0    3016.0       2.0   \n",
       "8413     h      S   Western Metropolitan      3      12.6    3020.0       3.0   \n",
       "2919     u     SP  Northern Metropolitan      3      13.0    3046.0       3.0   \n",
       "6043     h      S   Western Metropolitan      3      13.3    3020.0       3.0   \n",
       "\n",
       "       Bathroom  Landsize  Lattitude  Longtitude  Propertycount  \n",
       "12167       1.0       0.0  -37.85984    144.9867        13240.0  \n",
       "6524        2.0     193.0  -37.85800    144.9005         6380.0  \n",
       "8413        1.0     555.0  -37.79880    144.8220         3755.0  \n",
       "2919        1.0     265.0  -37.70830    144.9158         8870.0  \n",
       "6043        1.0     673.0  -37.76230    144.8272         4217.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, obtenemos una lista de todas las variables categóricas en los datos de entrenamiento.\n",
    "\n",
    "Hacemos esto comprobando el tipo de datos (o **dtype**) de cada columna. El objeto `dtype` indica que una columna tiene texto (hay otras cosas que en teoría podría ser, pero eso no es importante para nuestros propósitos). Para este conjunto de datos, las columnas con texto indican variables categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables categóricas:\n",
      "['Type', 'Method', 'Regionname']\n"
     ]
    }
   ],
   "source": [
    "# Obtiene la lista de variables categóricas\n",
    "s = (X_train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "print(\"Variables categóricas:\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definir la función para medir la calidad de cada enfoque\n",
    "\n",
    "Definimos una función `score_dataset()` para comparar los tres enfoques diferentes para tratar con variables categóricas. Esta función informa el [error absoluto medio](https://en.wikipedia.org/wiki/Mean_absolute_error) (MAE) de un modelo random forest. En general, ¡queremos que el MAE sea lo más bajo posible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Función para comparar diferentes enfoques\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Puntuación del Enfoque 1 (Eliminar variables categóricas)\n",
    "Eliminamos las columnas `object` con el método `select_dtypes()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE de Enfoque 1 (Eliminar variables categóricas):\n",
      "175703.48185157913\n"
     ]
    }
   ],
   "source": [
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
    "\n",
    "print(\"MAE de Enfoque 1 (Eliminar variables categóricas):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Puntuación del Enfoque 2 (Label Encoding)\n",
    "\n",
    "Scikit-learn tiene una clase `LabelEncoder` que se puede usar para obtener label encodings. Recorremos las variables categóricas y aplicamos el label encoder por separado a cada columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE de Enfoque 2 (Label Encoding):\n",
      "165936.40548390493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Hace una copia para evitar cambiar los datos originales\n",
    "label_X_train = X_train.copy()\n",
    "label_X_valid = X_valid.copy()\n",
    "\n",
    "# Aplica label encoder a cada columna con datos categóricos\n",
    "label_encoder = LabelEncoder()\n",
    "for col in object_cols:\n",
    "    label_X_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "    label_X_valid[col] = label_encoder.transform(X_valid[col])\n",
    "\n",
    "print(\"MAE de Enfoque 2 (Label Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el código anterior, para cada columna asignamos aleatoriamente cada valor único a un entero diferente. Este es un enfoque común que es más simple que proporcionar etiquetas personalizadas; sin embargo, podemos esperar un aumento adicional en el rendimiento si proporcionamos etiquetas mejor informadas para todas las variables ordinales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Puntuación del Enfoque 3 (One-Hot Encoding)\n",
    "\n",
    "Usamos la clase `OneHotEncoder` de scikit-learn para obtener codificaciones one-hot. Hay varios parámetros que se pueden usar para personalizar su comportamiento.\n",
    "\n",
    "+ Establecemos `handle_unknown = 'ignore'` para evitar errores cuando los datos de validación contienen clases que no están representadas en los datos de entrenamiento, y\n",
    "+ establecer `sparse = False` asegura que las columnas codificadas se devuelvan como una matriz numpy (en lugar de una matriz dispersa).\n",
    "\n",
    "Para usar el codificador, suministramos solo las columnas categóricas que queremos que estén codificadas one-hot. Por ejemplo, para codificar los datos de entrenamiento, proporcionamos `X_train[object_cols]`. (object_cols en el código a continuación es una lista de los nombres de columna con datos categóricos, por lo que `X_train[object_cols]` contiene todos los datos categóricos en el conjunto de entrenamiento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE de Enfoque 3 (One-Hot Encoding):\n",
      "166089.4893009678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Aplica one-hot encoder a cada columna con datos categóricos\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n",
    "\n",
    "# One-hot encoding elimina el índica; lo recuperamos\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# Elimina columnas categóricas (las reemplazará con one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# Añade columnas one-hot a características numéricas\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "print(\"MAE de Enfoque 3 (One-Hot Encoding):\") \n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué enfoque es el mejor?\n",
    "\n",
    "En este caso, eliminar las columnas categóricas (**Enfoque 1**) tuvo el peor desempeño, ya que tenía una valor MAE más alto. En cuanto a los otros dos enfoques, dado que los valores MAE devueltos tienen un valor tan cercano, no parece haber ningún beneficio significativo de uno sobre el otro.\n",
    "\n",
    "En general, one-hot encoding (**Enfoque 3**) funcionará mejor habitualmente y eliminar las columnas categóricas (**Enfoque 1**) generalmente funcionará peor, pero varía según el caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "\n",
    "El mundo está lleno de datos categóricos. ¡Serás un científico de datos mucho más efectivo si sabes cómo usar este tipo de datos tan común!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración\n",
    "\n",
    "En este ejercicio trabajaremos con datos de [Housing Prices Competition for Kaggle Learn Users](https://www.kaggle.com/c/home-data-for-ml-course). \n",
    "\n",
    "![Ames Housing dataset image](https://i.imgur.com/lTJVG4e.png)\n",
    "\n",
    "Vamos a cargar los conjuntos de entrenamiento y validación en `X_train`, `X_valid`, `y_train`, e `y_valid`.  El conjunto de pruebas es cargado en `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Lee los datos\n",
    "X = pd.read_csv('./input/train.csv', index_col='Id')\n",
    "X_test = pd.read_csv('./input/test.csv', index_col='Id')\n",
    "\n",
    "# Elimina las filas con objetivos ausentes, separa el objetivo de los predictores\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X.SalePrice\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# Para mantener las cosas simples solo usaremos predictores numéricos\n",
    "cols_with_missing = [col for col in X.columns if X[col].isnull().any()] \n",
    "X.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_test.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "# Separamos los datos de validación a partir de los datos de entrenamiento\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>11694</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NridgHt</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>6600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>30</td>\n",
       "      <td>RL</td>\n",
       "      <td>13360</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>13265</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Mitchel</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>13704</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSSubClass MSZoning  LotArea Street LotShape LandContour Utilities  \\\n",
       "Id                                                                        \n",
       "619          20       RL    11694   Pave      Reg         Lvl    AllPub   \n",
       "871          20       RL     6600   Pave      Reg         Lvl    AllPub   \n",
       "93           30       RL    13360   Pave      IR1         HLS    AllPub   \n",
       "818          20       RL    13265   Pave      IR1         Lvl    AllPub   \n",
       "303          20       RL    13704   Pave      IR1         Lvl    AllPub   \n",
       "\n",
       "    LotConfig LandSlope Neighborhood  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "Id                                    ...                                       \n",
       "619    Inside       Gtl      NridgHt  ...         108             0         0   \n",
       "871    Inside       Gtl        NAmes  ...           0             0         0   \n",
       "93     Inside       Gtl      Crawfor  ...           0            44         0   \n",
       "818   CulDSac       Gtl      Mitchel  ...          59             0         0   \n",
       "303    Corner       Gtl      CollgCr  ...          81             0         0   \n",
       "\n",
       "    ScreenPorch  PoolArea  MiscVal  MoSold  YrSold SaleType SaleCondition  \n",
       "Id                                                                         \n",
       "619         260         0        0       7    2007      New       Partial  \n",
       "871           0         0        0       8    2009       WD        Normal  \n",
       "93            0         0        0       8    2009       WD        Normal  \n",
       "818           0         0        0       7    2008       WD        Normal  \n",
       "303           0         0        0       1    2006       WD        Normal  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa que el conjunto de datos contiene variables numéricas y categóricas. Tendrás que codificar los datos categóricos antes de entrenar un modelo.\n",
    "\n",
    "Para comparar diferentes modelos, usarás la misma función `score_dataset()` del tutorial. Esta función informa el [error absoluto medio](https://en.wikipedia.org/wiki/Mean_absolute_error) (MAE) de un modelo random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# función para comparar diferentes enfoques\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1: eliminar columnas con datos categóricos\n",
    "\n",
    "Comenzarás con el enfoque más directo. Vamos a preprocesar los datos en `X_train` y `X_valid` para eliminar columnas con datos categóricos. Establece los DataFrames preprocesados en `drop_X_train` y `drop_X_valid`, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Enfoque 1 (Eliminar variables categóricas):\n",
      "17837.82570776256\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE Enfoque 1 (Eliminar variables categóricas):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: Label encoding\n",
    "\n",
    "Antes de saltar a label encoding, investigaremos el conjunto de datos. Específicamente, veremos la columna `Condition2`. El siguiente código imprime las entradas únicas en los conjuntos de entrenamiento y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en la columna 'Condition2' de los datos de entrenamiento: ['Norm' 'PosA' 'Feedr' 'PosN' 'Artery' 'RRAe']\n",
      "\n",
      "Valores únicos en la columna 'Condition2' de los datos de validación: ['Norm' 'RRAn' 'RRNn' 'Artery' 'Feedr' 'PosN']\n"
     ]
    }
   ],
   "source": [
    "print(\"Valores únicos en la columna 'Condition2' de los datos de entrenamiento:\", X_train['Condition2'].unique())\n",
    "print(\"\\nValores únicos en la columna 'Condition2' de los datos de validación:\", X_valid['Condition2'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ahora escribes código para:\n",
    "- entrenar un label encoder a los datos de entrenamiento, y luego\n",
    "- lo usas para transformar los datos de entrenamiento y validación,\n",
    "\n",
    "obtendrás un error. ¿Puedes ver por qué esto es así?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución**: Al entrenar un label encoder a una columna en los datos de entrenamiento se crea una etiqueta de valor entero para cada valor único **que aparece en los datos de entrenamiento**. En el caso de que los datos de validación contengan valores que no aparecen también en los datos de entrenamiento, el codificador arrojará un error, porque estos valores no tendrán un número entero asignado. Observe que la columna `Condition2` en los datos de validación contiene los valores `RRAn` y `RRNn`, pero estos no aparecen en los datos de entrenamiento; por lo tanto, si intentamos usar un label encoder con scikit-learn, el código arrojará un error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es un problema común que encontrarás con los datos del mundo real y hay muchos enfoques para solucionar este problema. Por ejemplo, puedes escribir un label encoder personalizado para tratar con nuevas categorías. Sin embargo, el enfoque más simple es eliminar las columnas categóricas problemáticas.\n",
    "\n",
    "Vamos a guardar las columnas problemáticas en una lista de Python `bad_label_cols`. Del mismo modo, las columnas que pueden codificarse de forma segura se almacenan en `good_label_cols`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas categóricas que serán label encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'LotConfig', 'BldgType', 'HouseStyle', 'ExterQual', 'CentralAir', 'KitchenQual', 'PavedDrive', 'SaleCondition']\n",
      "\n",
      "Colulmnas categóricas que serán eliinadas del dataset: ['SaleType', 'RoofStyle', 'ExterCond', 'Condition1', 'RoofMatl', 'Condition2', 'Neighborhood', 'Heating', 'Utilities', 'Exterior1st', 'Functional', 'HeatingQC', 'Exterior2nd', 'Foundation', 'LandSlope']\n"
     ]
    }
   ],
   "source": [
    "# Todas las columnas categóricas\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "# Columnas que pueden ser satisfactoriamente label encoded\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X_train[col]) == set(X_valid[col])]\n",
    "        \n",
    "# Columnas problemáticas que serán eliminadas del dataset\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "print('Columnas categóricas que serán label encoded:', good_label_cols)\n",
    "print('\\nColulmnas categóricas que serán eliinadas del dataset:', bad_label_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a label encode los datos en `X_train` y `X_valid`. Establece los DataFrames preprocesados en `label_X_train` y `label_X_valid`, respectivamente.\n",
    "- Hemos proporcionado el siguiente código para eliminar las columnas categóricas en `bad_label_cols` del conjunto de datos.\n",
    "- Debe label encode las columnas categóricas en `good_label_cols`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Drop categorical columns that will not be encoded\n",
    "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# Apply label encoder \n",
    "label_encoder = LabelEncoder()\n",
    "for col in good_label_cols:\n",
    "    label_X_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "    label_X_valid[col] = label_encoder.transform(X_valid[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Enfoque 2 (Label Encoding):\n",
      "17575.291883561644\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE Enfoque 2 (Label Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3 Investigando la cardinalidad\n",
    "\n",
    "Hasta ahora has probado dos enfoques diferentes para tratar con variables categóricas. Y has visto que codificar datos categóricos produce mejores resultados que eliminar columnas del conjunto de datos.\n",
    "\n",
    "Pronto intentará la codificación one-hot. Antes de eso hay un tema adicional que debemos cubrir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Street', 2),\n",
       " ('Utilities', 2),\n",
       " ('CentralAir', 2),\n",
       " ('LandSlope', 3),\n",
       " ('PavedDrive', 3),\n",
       " ('LotShape', 4),\n",
       " ('LandContour', 4),\n",
       " ('ExterQual', 4),\n",
       " ('KitchenQual', 4),\n",
       " ('MSZoning', 5),\n",
       " ('LotConfig', 5),\n",
       " ('BldgType', 5),\n",
       " ('ExterCond', 5),\n",
       " ('HeatingQC', 5),\n",
       " ('Condition2', 6),\n",
       " ('RoofStyle', 6),\n",
       " ('Foundation', 6),\n",
       " ('Heating', 6),\n",
       " ('Functional', 6),\n",
       " ('SaleCondition', 6),\n",
       " ('RoofMatl', 7),\n",
       " ('HouseStyle', 8),\n",
       " ('Condition1', 9),\n",
       " ('SaleType', 9),\n",
       " ('Exterior1st', 15),\n",
       " ('Exterior2nd', 16),\n",
       " ('Neighborhood', 25)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtiene el número de entradas únicas en cada columns con datos categóricos\n",
    "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "\n",
    "# Muestra el número de entradas únicas por columna, en orden ascendente\n",
    "sorted(d.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado anterior muestra, para cada columna con datos categóricos, el número de valores únicos. Por ejemplo, la columna `Street` en los datos de entrenamiento tiene dos valores únicos: `Grvl` y `Pave`, correspondientes a un camino de grava y un camino pavimentado, respectivamente.\n",
    "\n",
    "Nos referimos al número de entradas únicas de una variable categórica como la **cardinalidad** de esa variable categórica. Por ejemplo, la variable `Street` tiene cardinalidad 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Cuantas variables categóricas en los datos de entrenamiento tiene cardinalidad mayor de 10?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_cardinality_numcols = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cuántas columnas son necesarias para codificar one-hot la variable `Neighborhood` en los datos de entrenamiento?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_neighborhood = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para conjuntos de datos grandes con muchas filas, la codificación one-hot puede expandir en gran medida el tamaño del conjunto de datos. Por esta razón, normalmente solo codificaremos one-hot columnas con una cardinalidad relativamente baja. Luego las columnas de alta cardinalidad pueden eliminarse del conjunto de datos o podemos usar label encoding.\n",
    "\n",
    "Como ejemplo, considere un conjunto de datos con 10.000 filas y que contenga una columna categórica con 100 entradas únicas.\n",
    "- Si esta columna se reemplaza con la codificación one-hot, ¿cuántas entradas se agregan al conjunto de datos?\n",
    "- Si en su lugar reemplazamos la columna con label encoding, ¿cuántas entradas se agregan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "OH_entries_added = (10000 * 100) - 10000\n",
    "label_entries_added = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
