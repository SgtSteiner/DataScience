{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje Automático - Intermedio\n",
    "\n",
    "## Valores ausentes\n",
    "\n",
    "### Introducción\n",
    "\n",
    "En este tutorial, aprenderemos tres enfoques para tratar los valores ausentes. Luego compararemos la efectividad de estos enfoques en un conjunto de datos del mundo real.\n",
    "\n",
    "Hay muchas formas en las que los datos pueden terminar con valores ausentes. Por ejemplo,\n",
    "\n",
    "+ Una casa de 2 dormitorios no incluirá un valor para el tamaño de un tercer dormitorio.\n",
    "+ Un encuestado puede optar por no compartir sus ingresos.\n",
    "\n",
    "La mayoría de las librerías de aprendizaje automático (incluido scikit-learn) dan un error si intentamos construir un modelo utilizando datos con valores faltantes. Por lo tanto, deberemos elegir una de las estrategias a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tres enfoques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Opción simple: Eliminar las columnas con valores faltantes\n",
    "\n",
    "La opción más simple es eliminar las columnas con valores faltantes.\n",
    "\n",
    "![Opción1](./images/valores_faltantes_1.png)\n",
    "\n",
    "A menos que falten la mayoría de los valores en las columnas descartadas, el modelo pierde acceso a mucha información (¡potencialmente útil!) con este enfoque. Como ejemplo extremo, considere un conjunto de datos con 10.000 filas, donde a una columna importante le falta una sola entrada. ¡Este enfoque eliminaría la columna por completo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Una mejor opción: Imputación\n",
    "\n",
    "La **imputación** completa los valores faltantes con algún número. Por ejemplo, podemos completar el valor medio a lo largo de cada columna.\n",
    "\n",
    "![Valores_faltantes_2](./images/valores_faltantes_2.png)\n",
    "\n",
    "El valor imputado no será exactamente correcto en la mayoría de los casos, pero generalmente conduce a modelos más precisos de los que obtendría al eliminar la columna por completo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Una extesión a la imputacion\n",
    "\n",
    "La imputación es el enfoque estándar y generalmente funciona bien. Sin embargo, los valores imputados pueden estar sistemáticamente por encima o por debajo de sus valores reales (que no se recopilaron en el conjunto de datos). O las filas con valores ausentes pueden ser únicas de alguna otra manera. En ese caso, tu modelo haría mejores predicciones al considerar qué valores faltaban originalmente.\n",
    "\n",
    "![valores_faltantes_3](./images/valores_faltantes_3.png)\n",
    "\n",
    "En este enfoque imputamos los valores ausentes como antes. Y, además, para cada columna con entradas faltantes en el conjunto de datos original, agregamos una nueva columna que muestra la ubicación de las entradas imputadas.\n",
    "\n",
    "En algunos casos, esto mejorará significativamente los resultados. En otros casos, no ayuda en absoluto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo, trabajaremos con el conjunto de datos de [Melbourne Housing](https://www.kaggle.com/dansbecker/melbourne-housing-snapshot). Nuestro modelo utilizará información como la cantidad de habitaciones y el tamaño del terreno para predecir el precio de la vivienda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carga los data\n",
    "data = pd.read_csv('./input/melbourne-housing-snapshot/melb_data.csv')\n",
    "\n",
    "# Selecciona el objetivo\n",
    "y = data.Price\n",
    "\n",
    "# Para mantener las cosas simples, usaremos solo predictores numéricos\n",
    "melb_predictors = data.drop(['Price'], axis=1)\n",
    "X = melb_predictors.select_dtypes(exclude=['object'])\n",
    "\n",
    "# divide los datos en entrenamiento y validación\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define la función para medir la calidad de cada enfoque\n",
    "\n",
    "Definimos una función `score_dataset()` para comparar los diferentes enfoques de tratar los valores perdidos. Esta función informa el error absoluto medio (MAE) de un modelo de random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Función para comparar diferentes enfoques\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=10, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Puntuación del Enfoque 1 (Eliminar columnas con valores ausentes)\n",
    "\n",
    "Como estamos trabajando con conjuntos de entrenamiento y validación, tenemos cuidado de eliminar las mismas columnas en ambos dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE de Enfoque 1 (Eliminar columnas con valores ausentes):\n",
      "183550.22137772635\n"
     ]
    }
   ],
   "source": [
    "# Obtiene los nombres de las columnas con valores ausentes\n",
    "cols_with_missing = [col for col in X_train.columns\n",
    "                     if X_train[col].isnull().any()]\n",
    "\n",
    "# Elimina las columnas en datos de entrenamiento y validación\n",
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\n",
    "\n",
    "print(\"MAE de Enfoque 1 (Eliminar columnas con valores ausentes):\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Puntuación del Enfoque 2 (Imputación)\n",
    "\n",
    "Usamos `SimpleImputer` para reemplazar los valores faltantes con el valor medio a lo largo de cada columna.\n",
    "\n",
    "Aunque es simple, completar el valor medio generalmente funciona bastante bien (pero esto varía según el conjunto de datos). Si bien los estadísticos han experimentado formas más complejas de determinar los valores imputados (como la **imputación de regresión**, por ejemplo), las estrategias complejas generalmente no brindan ningún beneficio adicional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE de Enfoque 2 (Imputación):\n",
      "178166.46269899711\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imputación\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "# La imputación elimina los nombres de las columnas; los recuperamos\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns\n",
    "\n",
    "print(\"MAE de Enfoque 2 (Imputación):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el Enfoque 2 tiene un MAE más bajo que el Enfoque 1, por lo que el Enfoque 2 se ejecutó mejor en este conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
